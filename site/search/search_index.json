{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Strona g\u0142\u00f3wna","text":""},{"location":"#data-backbone-odkryj-wartosc-swoich-danych-biznesowych","title":"Data Backbone - Odkryj warto\u015b\u0107 swoich danych biznesowych","text":""},{"location":"#kregosup-danych","title":"Kr\u0119gos\u0142up danych","text":"<p>Jeste\u015bmy Usprawniacze Firm i stworzyli\u015bmy narz\u0119dzie, kt\u00f3re pomo\u017ce Twojej firmie odkry\u0107 now\u0105 wiedz\u0119 i warto\u015b\u0107 ukryt\u0105 we w\u0142asnych danych.</p> <p>I odzyskaj spok\u00f3j i kontrol\u0119 w technologicznej sferze Twojej firmy</p>"},{"location":"#czym-jest-data-backbone","title":"Czym jest Data Backbone?","text":"<p>Data Backbone to platforma, kt\u00f3ra u\u0142atwia ma\u0142ym i \u015brednim przedsi\u0119biorstwom (M\u015aP) analiz\u0119 danych z r\u00f3\u017cnych \u017ar\u00f3de\u0142. Wyobra\u017a sobie, \u017ce masz dost\u0119p do wszystkich swoich danych biznesowych w jednym miejscu - od emaili, przez dane z CRM, a\u017c po firmowe excele. Data Backbone pomo\u017ce Ci po\u0142\u0105czy\u0107 te dane i wyci\u0105gn\u0105\u0107 z nich warto\u015bciowe wnioski.</p>"},{"location":"#jak-data-backbone-moze-pomoc-twojej-firmie","title":"Jak Data Backbone mo\u017ce pom\u00f3c Twojej firmie?","text":"<p>Za\u0142\u00f3\u017cmy, \u017ce chcesz wiedzie\u0107, ile mar\u017cy generujesz na ka\u017cdym z klient\u00f3w w uj\u0119ciu miesi\u0119cznym. Data Backbone pozwoli Ci po\u0142\u0105czy\u0107 dane z systemu rejestracji czasu pracy (np. Clickup), dane o pensjach pracownik\u00f3w z excela oraz informacje o przep\u0142ywach finansowych z konta bankowego. W rezultacie otrzymasz przejrzysty raport pokazuj\u0105cy mar\u017c\u0119 dla ka\u017cdego klienta.</p>"},{"location":"concepts/indicators/","title":"Wska\u017aniki","text":""},{"location":"concepts/indicators/#wprowadzenie","title":"Wprowadzenie","text":"<p>Aby stworzy\u0107 nowy wska\u017anik w systemie Data Backbone, post\u0119puj zgodnie z poni\u017cszymi krokami. Wska\u017anik to metryka, kt\u00f3ra pozwala na analiz\u0119 i monitorowanie r\u00f3\u017cnych aspekt\u00f3w biznesowych na podstawie przetworzonych danych.</p>"},{"location":"concepts/indicators/#definicja-struktury-wskaznika","title":"Definicja Struktury Wska\u017anika","text":""},{"location":"concepts/indicators/#typ-wskaznika","title":"Typ wska\u017anika","text":"<pre><code>@dataclass\nclass RequiredFields:\n    id: str # wskazanie klucza id w zasobie\n    updated: str # wskazanie klucza ostatniej modyfikacji w zasobie\n\n# typ wska\u017anika\n@dataclass\nclass Indicator:\n    name: str # nazwa wska\u017anika, jest to tak\u017ce nazwa kolekcji Mongo w bazie \"INDICATORS\"\n    description: str # opis wska\u017anika\n    department: str # opis dzia\u0142u, do kt\u00f3rego przypisany jest wska\u017anik\n    fields: RequiredFields # pola wymagane  do zmapowania we wska\u017anika\n    action: str # nazwa akcji przetwarzaj\u0105cej dane do wska\u017anika. to jest referencja po kluczu do typu IndicatorAction\n    out_action: str # nazwa akcji wystawiaj\u0105cej dane wska\u017anika z zewn\u0119trznym oprogramowaniem. to jest referencja po kluczu do typu IndicatorOutAction\n\n# typ zawarto\u015bci zasobu\nResourceData = List[Dict[str, Any]]\n\n# typ akcji przetwarzaj\u0105cej dane do wska\u017anika\nIndicatorAction = Callable[\n    [Indicator, MongoClient],\n    ResourceData\n]\n\n# typ akcji wystawiaj\u0105cej dane wska\u017anika dla zewn\u0119trznego oprogramowania\nIndicatorOutAction = Callable[\n    [Indicator, ResourceData, MongoClient],\n    Any\n]\n</code></pre>"},{"location":"concepts/indicators/#struktura-wskaznika","title":"Struktura wska\u017anika","text":"<p>Struktura wska\u017anika zosta\u0142a zdefiniowana w pliku JSON, kt\u00f3ry nale\u017cy utworzy\u0107 i wype\u0142ni\u0107 zgodnie z poni\u017cszym szablonem:</p> <pre><code>{\n  \"name\": \"ExampleIndicatorBoilerplate\",\n  \"department\": \"finance\",\n  \"description\": \"Example description for example indicator\",\n  \"fields\": {\n    \"id\": \"id\",\n    \"updated\": \"last_updated_time\"\n  },\n  \"action\": \"calculate_example_indicator\"\n}\n</code></pre>"},{"location":"concepts/indicators/#opis-pol-wskaznika","title":"Opis p\u00f3l Wska\u017anika:","text":"<ul> <li>name: (string) Nazwa wska\u017anika. Jest to tak\u017ce nazwa kolekcji Mongo w bazie \"INDICATORS\".</li> <li>department: (string) Dzia\u0142, do kt\u00f3rego przypisany jest wska\u017anik, np. \"marketing\", \"finanse\".</li> <li>description: (string) Opis wska\u017anika, zawieraj\u0105cy informacje o przeznaczeniu i zawarto\u015bci wska\u017anika.</li> <li>fields: (object) Pola wymagane do zmapowania w wska\u017aniku:</li> <li>id: (string) Klucz g\u0142\u00f3wny identyfikuj\u0105cy wska\u017anik w jego docelowym API.</li> <li>updated: (string) Klucz ostatniej modyfikacji wska\u017anika w jego docelowym API.</li> <li>action: (string) Nazwa akcji przetwarzaj\u0105cej dane. Jest to referencja do funkcji, kt\u00f3ra przetwarza dane z zasob\u00f3w do wska\u017anika.</li> </ul>"},{"location":"concepts/indicators/#tworzenie-pliku-krok-po-kroku","title":"Tworzenie pliku krok po kroku:","text":"<ol> <li>Utw\u00f3rz nowy plik JSON (np. <code>MonthlyMargin.json</code>).</li> <li>Wklej powy\u017csz\u0105 struktur\u0119 do pliku.</li> <li>Zapisz plik w katalogu <code>/__indicators__/boilerplates/MonthlyMargin.json</code></li> </ol>"},{"location":"concepts/indicators/#przykadowa-struktura-json-wskaznika","title":"Przyk\u0142adowa struktura JSON wska\u017anika:","text":"<pre><code>{\n  \"name\": \"MonthlyMargin\",\n  \"department\": \"finance\",\n  \"description\": \"Wska\u017anik mar\u017cy miesi\u0119cznej dla ka\u017cdego klienta\",\n  \"fields\": {\n    \"id\": \"client_id\",\n    \"updated\": \"last_calculated\"\n  },\n  \"action\": \"calculate_monthly_margin\"\n}\n</code></pre>"},{"location":"concepts/intro/","title":"Koncept zasobu i wska\u017anika","text":""},{"location":"concepts/intro/#czym-jest-zasob","title":"Czym jest zas\u00f3b","text":"<p>Koncept zasobu odnosi si\u0119 do po\u0142\u0105czenia opisu</p>"},{"location":"concepts/intro/#czym-jest-wskaznik","title":"Czym jest wska\u017anik","text":"<p>Koncept zasobu odnosi si\u0119 do abstrakcyjnego przedstawienia danych lub funkcji, kt\u00f3re s\u0105 dost\u0119pne w systemie, umo\u017cliwiaj\u0105c ich \u0142atwe zarz\u0105dzanie i integracj\u0119. Zasoby mog\u0105 reprezentowa\u0107 r\u00f3\u017cnorodne elementy, takie jak dane finansowe, u\u017cytkownicy czy transakcje, i s\u0105 cz\u0119sto wykorzystywane w aplikacjach do organizacji i strukturyzacji informacji.</p>"},{"location":"concepts/intro/#struktura-json-zasobu","title":"Struktura JSON Zasobu","text":"<pre><code>{\n  \"name\": \"StripeInvoices\",\n  \"description\": \"Zas\u00f3b faktur ze Stripe\",\n  \"department\": \"finance\",\n  \"fields\": {\n    \"id\": \"id\",\n    \"updated\": \"created\"\n  },\n  \"action\": \"fetch_stripe_invoices\"\n}\n</code></pre>"},{"location":"concepts/intro/#skadowe-funkcji-fetch_stripe_invoices","title":"Sk\u0142adowe funkcji fetch_stripe_invoices:","text":"<ul> <li>Niezb\u0119dne zale\u017cno\u015bci do realizacji logiki biznesowej</li> <li>Schema walidacji danych wychodz\u0105cych</li> <li>Cz\u0119\u015bci akcji pobierania zasobu</li> <li>Funkcje collect</li> <li>Funkcja morph_json_with_pandas</li> <li>Funkcja validate_output</li> <li>Ca\u0142y kod akcji pobierania zasobu</li> </ul>"},{"location":"concepts/intro/#1-niezbedne-zaleznosci-do-realizacji-logiki-biznesowej","title":"1. Niezb\u0119dne zale\u017cno\u015bci do realizacji logiki biznesowej","text":"<pre><code>import pandas as pd  # Import Pandas do pracy z danymi w formie tabel\nfrom dotenv import load_dotenv  # Import funkcji load_dotenv do \u0142adowania zmiennych \u015brodowiskowych z pliku .env\nfrom __resources__.types import Resource, MongoClient\nfrom external_services.stripe.utils import check_if_metadata_exists\nfrom external_services.stripe.stripe_client import collect_invoices_from_stripe, collect_missing_invoices  # Import funkcji do pobierania faktur z Stripe\nfrom typing import List, Dict, Any  # Import typ\u00f3w dla adnotacji\nfrom utils.validator import Validator\n</code></pre>"},{"location":"concepts/intro/#2-schema-walidacji-danych-wychodzacych","title":"2. Schema walidacji danych wychodz\u0105cych","text":"<pre><code>schema_out = {\n    \"id\": str,\n    \"amount_paid\": float,\n    \"total\": float,\n    \"created\": int,\n    \"status\": str,\n    \"customer\": str,\n    \"hours_capacity_per_payment\": int\n}\n</code></pre>"},{"location":"concepts/intro/#3-akcja-pobierania-zasobu","title":"3. Akcja pobierania zasobu","text":""},{"location":"concepts/intro/#3a-funkcje-collect","title":"3a. Funkcje collect","text":"<pre><code># implementacja\n\nimport requests  # Import modu\u0142u requests do wykonywania \u017c\u0105da\u0144 HTTP\nfrom dotenv import load_dotenv  # Import funkcji load_dotenv do \u0142adowania zmiennych \u015brodowiskowych z pliku .env\nimport os  # Import modu\u0142u os do pracy z systemem operacyjnym\n\ndef collect_invoices_from_stripe(accumulator:list=[]):\n    NUMBER_OF_MISSING_INVOICES = 3\n    load_dotenv()  # Za\u0142aduj zmienne \u015brodowiskowe z pliku .env\n    STRIPE_KEY = os.getenv('STRIPE_KEY')  # Pobierz klucz API Stripe ze zmiennych \u015brodowiskowych\n    headers = {\n        \"Authorization\": f\"Bearer {STRIPE_KEY}\"  # Ustaw nag\u0142\u00f3wki autoryzacyjne dla \u017c\u0105da\u0144 HTTP\n    }\n\n    invoices = accumulator  # Inicjalizuj list\u0119 faktur\n\n    if len(invoices) == NUMBER_OF_MISSING_INVOICES:\n        url = \"https://api.stripe.com/v1/invoices?status=paid&amp;limit=100\"  # URL do pobierania faktur z Stripe\n    if len(invoices) &gt; NUMBER_OF_MISSING_INVOICES:\n        url = f\"https://api.stripe.com/v1/invoices?status=paid&amp;limit=100&amp;starting_after={invoices[-1]['id']}\"\n\n    response = requests.get(url, headers=headers)  # Wykonaj \u017c\u0105danie HTTP GET do API Stripe\n\n    if response.status_code != 200:  # Sprawd\u017a, czy odpowied\u017a ma status 200 (OK)\n        raise Exception(f\"B\u0142\u0105d podczas pobierania danych z collect_invoices_from_stripe. Kod statusu: {response.status_code}\")  # Rzu\u0107 wyj\u0105tek w przypadku b\u0142\u0119du\n\n    data = response.json()['data']  # Pobierz dane JSON z odpowiedzi\n    if not data:  # Sprawd\u017a, czy dane s\u0105 puste\n        return invoices  # Zako\u0144cz rekurencj\u0119 i zwr\u00f3\u0107 faktury\n\n    invoices.extend(data)  # Dodaj pobrane faktury do listy invoices\n    return collect_invoices_from_stripe(invoices)\n\n\n# u\u017cycie\n\nfrom external_services.stripe.utils import check_if_metadata_exists\nfrom external_services.stripe.stripe_client import collect_invoices_from_stripe, collect_missing_invoices  # Import funkcji do pobierania faktur z Stripe\n\n\n\"\"\"Pobierz i przekszta\u0142\u0107 faktury ze Stripe\"\"\"\nmissing_invoices = collect_missing_invoices()  # Pobranie brakuj\u0105cych faktur ze Stripe\nall_stripe_invoices = collect_invoices_from_stripe(missing_invoices)  # Pobranie wszystkich faktur ze Stripe\n</code></pre>"},{"location":"concepts/intro/#3b-funkcja-morph_json_with_pandas","title":"3b. Funkcja morph_json_with_pandas","text":"<pre><code>def morph_json_with_pandas(data: List[Dict[str, Any]]) -&gt; List[Dict[str, Any]]:\n    \"\"\"Przekszta\u0142\u0107 dane JSON na DataFrame i przefiltruj kolumny\"\"\"\n    columns_wanted = [\n        'id', 'amount_paid', 'lines', 'total', 'created',\n        'status', 'customer'\n    ]  # Definicja kolumn, kt\u00f3re chcemy zachowa\u0107\n\n    df = pd.DataFrame(data)  # Stworzenie DataFrame z danych JSON\n    df = df[columns_wanted]  # Zachowanie tylko wybranych kolumn w DataFrame\n\n    df['created'] = df['created'].astype(int)  # Przekszta\u0142cenie kolumny 'created' na typ int\n\n    # Przypisanie warto\u015bci do odpowiednich kolumn\n    df['id'] = df['id']\n    df['amount_paid'] = df['amount_paid']\n    df['hours_capacity_per_payment'] = df.apply(lambda x: int(x['lines']['data'][0]['plan']['metadata']['hours_capacity_per_payment']), axis=1)\n    df['total'] = df['total']\n    df['status'] = df['status']\n    df['customer'] = df['customer']\n\n    df.drop(['lines'], axis=1, inplace=True)\n\n    return df\n</code></pre>"},{"location":"concepts/intro/#3c-funkcja-validate_output","title":"3c. Funkcja validate_output","text":"<pre><code>def validate_output(df, schema_out):\n\n    return Validator.validate(df,schema_out)\n</code></pre>"},{"location":"concepts/intro/#4-cay-kod-akcji-pobierania-zasobu","title":"4. Ca\u0142y kod akcji pobierania zasobu","text":"<pre><code>import pandas as pd  # Import Pandas do pracy z danymi w formie tabel\nfrom dotenv import load_dotenv  # Import funkcji load_dotenv do \u0142adowania zmiennych \u015brodowiskowych z pliku .env\nfrom __resources__.types import Resource, MongoClient\nfrom external_services.stripe.utils import check_if_metadata_exists\nfrom external_services.stripe.stripe_client import collect_invoices_from_stripe, collect_missing_invoices  # Import funkcji do pobierania faktur z Stripe\nfrom typing import List, Dict, Any  # Import typ\u00f3w dla adnotacji\nfrom utils.validator import Validator\n\n\nschema_out = {\n    \"id\": str,\n    \"amount_paid\": float,\n    \"total\": float,\n    \"created\": int,\n    \"status\": str,\n    \"customer\": str,\n    \"hours_capacity_per_payment\": int\n}\n\n\ndef morph_json_with_pandas(data: List[Dict[str, Any]]) -&gt; List[Dict[str, Any]]:\n    \"\"\"Przekszta\u0142\u0107 dane JSON na DataFrame i przefiltruj kolumny\"\"\"\n    columns_wanted = [\n        'id', 'amount_paid', 'lines', 'total', 'created',\n        'status', 'customer'\n    ]  # Definicja kolumn, kt\u00f3re chcemy zachowa\u0107\n\n    df = pd.DataFrame(data)  # Stworzenie DataFrame z danych JSON\n    df = df[columns_wanted]  # Zachowanie tylko wybranych kolumn w DataFrame\n\n    df['created'] = df['created'].astype(int)  # Przekszta\u0142cenie kolumny 'created' na typ int\n\n    # Przypisanie warto\u015bci do odpowiednich kolumn\n    df['id'] = df['id']\n    df['amount_paid'] = df['amount_paid']\n    df['hours_capacity_per_payment'] = df.apply(lambda x: int(x['lines']['data'][0]['plan']['metadata']['hours_capacity_per_payment']), axis=1)\n    df['total'] = df['total']\n    df['status'] = df['status']\n    df['customer'] = df['customer']\n\n    df.drop(['lines'], axis=1, inplace=True)  # Usuni\u0119cie kolumny 'lines' z DataFrame\n    return df\n\n\ndef validate_output(df, schema_out):\n    \"\"\"Waliduje dane w DataFrame zgodnie z podanym schematem.\"\"\"\n    return Validator.validate(df, schema_out)\n\n\ndef fetch_stripe_invoices(resource_setting: Resource, mongo_client: MongoClient) -&gt; List[Dict[str, Any]]:\n    \"\"\"Pobierz i przekszta\u0142\u0107 faktury ze Stripe\"\"\"\n\n    missing_invoices = collect_missing_invoices()  # Pobranie brakuj\u0105cych faktur ze Stripe\n    all_stripe_invoices = collect_invoices_from_stripe(missing_invoices)  # Pobranie wszystkich faktur ze Stripe\n\n    df_invoices = pd.DataFrame(all_stripe_invoices)  # Stworzenie DataFrame ze wszystkich faktur\n\n    # Przefiltrowanie faktur, aby usun\u0105\u0107 te z okre\u015blonymi ID\n    filtered_all_invoices = df_invoices[~df_invoices['id'].isin(['in_1PTOUuE2fekoERPNjIgQdiNh', 'in_1PXip9E2fekoERPNATlFnNUR'])].to_dict('records')\n    df_invoices = pd.DataFrame(filtered_all_invoices)\n\n    df_invoices['lines'] = df_invoices['lines'].apply(check_if_metadata_exists)\n\n    filtered_all_invoices = df_invoices.to_dict(orient='records')\n\n    filtered_all_invoices = df_invoices.to_dict(orient='records')\n\n    complete_invoices = morph_json_with_pandas(filtered_all_invoices)\n\n    complete_invoices = validate_output(complete_invoices, schema_out)\n\n    dict_invoices = complete_invoices.to_dict(orient='records')\n\n    return dict_invoices  # Zwr\u00f3cenie kompletnych faktur\n</code></pre>"},{"location":"concepts/pattern/","title":"Pattern","text":"<p>Struktura do generowania opisu do koncept\u00f3w</p>"},{"location":"concepts/pattern/#nazwa-konceptu","title":"Nazwa Konceptu","text":"<p>Kr\u00f3tki opis konceptu i jego g\u0142\u00f3wnego celu.</p>"},{"location":"concepts/pattern/#lokalizacja-w-projekcie","title":"Lokalizacja w Projekcie","text":"<ul> <li>\u015acie\u017cka do pliku/modu\u0142u: <code>src/module/concept.py</code></li> <li>Linie kodu: 100-250</li> </ul>"},{"location":"concepts/pattern/#zaozenia","title":"Za\u0142o\u017cenia","text":"<ul> <li>Lista kluczowych za\u0142o\u017ce\u0144, na kt\u00f3rych opiera si\u0119 koncept</li> <li>Ograniczenia i warunki brzegowe</li> </ul>"},{"location":"concepts/pattern/#wymagania","title":"Wymagania","text":"<ul> <li>Zale\u017cno\u015bci systemowe</li> <li>Wymagane biblioteki i ich wersje</li> <li>Inne niezb\u0119dne zasoby</li> </ul>"},{"location":"concepts/pattern/#struktury-danych","title":"Struktury Danych","text":""},{"location":"concepts/pattern/#kod","title":"Kod","text":""},{"location":"concepts/pattern/#interfejs-api","title":"Interfejs API","text":"<ul> <li>Opis publicznych metod i funkcji</li> <li>Przyk\u0142ady u\u017cycia</li> </ul>"},{"location":"concepts/pattern/#obsuga-bedow","title":"Obs\u0142uga B\u0142\u0119d\u00f3w","text":"<ul> <li>Lista mo\u017cliwych wyj\u0105tk\u00f3w</li> <li>Strategie obs\u0142ugi b\u0142\u0119d\u00f3w</li> </ul>"},{"location":"concepts/pattern/#testy","title":"Testy","text":"<ul> <li>Opis test\u00f3w jednostkowych</li> <li>Scenariusze testowe</li> </ul>"},{"location":"concepts/pattern/#znane-ograniczenia","title":"Znane Ograniczenia","text":"<ul> <li>Lista znanych ogranicze\u0144 lub problem\u00f3w</li> <li>Planowane ulepszenia</li> </ul>"},{"location":"concepts/resources/","title":"Zasoby","text":""},{"location":"concepts/resources/#wprowadzenie","title":"Wprowadzenie","text":"<p>Ten przewodnik przeprowadzi Ci\u0119 przez proces tworzenia nowego zasobu w systemie Data Backbone. Zas\u00f3b to struktura danych, kt\u00f3ra pozwala na gromadzenie i zarz\u0105dzanie danymi z r\u00f3\u017cnych \u017ar\u00f3de\u0142.</p>"},{"location":"concepts/resources/#definicja-struktury-zasobu","title":"Definicja Struktury Zasobu","text":""},{"location":"concepts/resources/#typ-zasobu","title":"Typ zasobu:","text":"<pre><code>@dataclass\nclass RequiredFields:\n    id: str # wskazanie klucza id w zasobie\n    updated: str # wskazanie klucza ostatniej modyfikacji w zasobie\n\n# typ zasobu\n@dataclass\nclass Resource:\n    name: str # nazwa zasobu, jest to tak\u017ce nazwa kolekcji Mongo w bazie \"RESOURCES\"\n    description: str # opis zasobu\n    department: str # opis dzia\u0142u, do kt\u00f3rego przypisany jest zas\u00f3b\n    fields: RequiredFields # pola wymagane  do zmapowania w zasobie\n    action: str # nazwa akcji pobieraj\u0105cej dane. to jest referencja po kluczu do ResourceAction\n\n# typ zawarto\u015bci zasobu\nResourceData = List[Dict[str, Any]]\n\n# typ akcji pobieraj\u0105cej zas\u00f3b\nResourceAction = Callable[\n    [Resource, MongoClient],\n    ResourceData\n]\n</code></pre>"},{"location":"concepts/resources/#struktura-zasobu","title":"Struktura zasobu","text":"<p>Zas\u00f3b jest definiowany w formacie JSON. Przyk\u0142adowa struktura zasobu wygl\u0105da nast\u0119puj\u0105co:</p> <pre><code>{\n  \"name\": \"ExampleResourceBoilerplate\",\n  \"department\": \"ops\",\n  \"description\": \"Example description for example resource\",\n  \"fields\": {\n    \"id\": \"id\",\n    \"updated\": \"last_updated_time\"\n  },\n  \"action\": \"give_me_example_data\"\n}\n</code></pre>"},{"location":"concepts/resources/#opis-pol-zasobu","title":"Opis P\u00f3l Zasobu","text":"<ul> <li>name: (string) Nazwa zasobu, jest to tak\u017ce nazwa kolekcji Mongo w bazie \"RESOURCES\".</li> <li>department: (string) Dzia\u0142, do kt\u00f3rego przypisany jest zas\u00f3b, np. \"marketing\", \"finanse\".</li> <li>description: (string) Opis zasobu, zawieraj\u0105cy informacje o przeznaczeniu i zawarto\u015bci zasobu.</li> <li>fields: (object) Pola wymagane do zmapowania w zasobie:</li> <li>id: (string) Klucz g\u0142\u00f3wny identyfikuj\u0105cy zas\u00f3b w jego docelowym API.</li> <li>updated: (string) Klucz ostatniej modyfikacji zasobu w jego docelowym API.</li> <li>action: (string) Nazwa akcji pobieraj\u0105cej dane. Jest to referencja do funkcji, kt\u00f3ra pobiera dane z zewn\u0119trznego \u017ar\u00f3d\u0142a.</li> </ul>"},{"location":"concepts/resources/#tworzenie-pliku-krok-po-kroku","title":"Tworzenie pliku krok po kroku:","text":"<ol> <li>Utw\u00f3rz nowy plik JSON (np. <code>ExampleResourceBoilerplate.json</code>).</li> <li>Wklej powy\u017csz\u0105 struktur\u0119 do pliku.</li> <li>Zapisz plik w katalogu <code>/__resources__/boilerplates/ExampleResourceBoilerplate.json</code></li> </ol>"},{"location":"concepts/resources/#przykadowe-struktury-zasobu","title":"Przyk\u0142adowe Struktury Zasobu","text":""},{"location":"concepts/resources/#przykad-1-zasob-dla-kampanii-marketingowych","title":"Przyk\u0142ad 1: Zas\u00f3b dla Kampanii Marketingowych","text":"<pre><code>{\n  \"name\": \"MarketingCampaigns\",\n  \"department\": \"marketing\",\n  \"description\": \"Dane dotycz\u0105ce kampanii marketingowych z Google Ads\",\n  \"fields\": {\n    \"id\": \"campaign_id\",\n    \"updated\": \"last_updated\"\n  },\n  \"action\": \"fetch_marketing_campaign_data\"\n}\n</code></pre>"},{"location":"concepts/resources/#przykad-2-zasob-dla-transakcji-finansowych","title":"Przyk\u0142ad 2: Zas\u00f3b dla Transakcji Finansowych","text":"<pre><code>{\n  \"name\": \"FinancialTransactions\",\n  \"department\": \"finance\",\n  \"description\": \"Dane dotycz\u0105ce transakcji finansowych z konta bankowego\",\n  \"fields\": {\n    \"id\": \"transaction_id\",\n    \"updated\": \"transaction_date\"\n  },\n  \"action\": \"fetch_financial_transactions\"\n}\n</code></pre>"},{"location":"concepts/validation/","title":"Schematy walidacji","text":""},{"location":"concepts/validation/#wprowadzenie","title":"Wprowadzenie","text":"<p>Klasa <code>Validator</code> s\u0142u\u017cy do walidacji obiekt\u00f3w <code>DataFrame</code> z biblioteki Pandas zgodnie z okre\u015blonym schematem. Umo\u017cliwia sprawdzenie poprawno\u015bci typ\u00f3w danych w kolumnach DataFrame'a na podstawie dostarczonego schematu.</p>"},{"location":"concepts/validation/#argument-schema","title":"Argument Schema","text":""},{"location":"concepts/validation/#schema_out","title":"schema_out","text":"<p><code>schema_out</code> jest argumentem przekazywanym do Validatora, zdefiniowanym jako zagnie\u017cd\u017cony s\u0142ownik, gdzie klucze reprezentuj\u0105 nazwy p\u00f3l, a warto\u015bci reprezentuj\u0105 oczekiwane typy danych. W schemacie <code>schema_out</code>, warto\u015bci, takie jak <code>str</code>, <code>int</code> i <code>float</code>, to klasy wbudowane w Pythonie i reprezentuj\u0105 typy danych.</p>"},{"location":"concepts/validation/#przykad-schema_out","title":"Przyk\u0142ad schema_out","text":"<pre><code>schema_out = {\n    \"client\": str,\n    \"id\": str,\n    \"date\": str,\n    \"cycles_with_invoices\": [\n        {\n            \"id\": str,\n            \"cycle_number\": int,\n            \"date_of_payment\": str,\n            \"end_of_cycle\": str,\n            \"total_hours_with_buffer\": float,\n            \"remaining_hours_with_buffer\": float,\n            \"programmers\": [\n                {\n                    \"user_name\": str,\n                    \"worked_time\": float\n                }\n            ],\n            \"worked_time\": float,\n            \"hour_cap\": float\n        }\n    ]\n}\n</code></pre>"},{"location":"concepts/validation/#metody-klasy-validator","title":"Metody klasy Validator","text":""},{"location":"concepts/validation/#1-validate","title":"1. <code>validate</code>","text":"<p>Waliduje DataFrame zgodnie z podanym schematem. Sprawdza, czy wszystkie wymagane kolumny s\u0105 obecne oraz czy warto\u015bci w poszczeg\u00f3lnych kolumnach odpowiadaj\u0105 oczekiwanym typom. W przypadku b\u0142\u0119d\u00f3w zg\u0142asza wyj\u0105tek.</p>"},{"location":"concepts/validation/#argumenty","title":"Argumenty","text":"<ul> <li><code>df</code> (pd.DataFrame): DataFrame do walidacji.</li> <li><code>schema</code> (Dict[str, Any]): Schemat definiuj\u0105cy oczekiwane typy dla kolumn.</li> </ul>"},{"location":"concepts/validation/#zwraca","title":"Zwraca","text":"<ul> <li><code>pd.DataFrame</code>: Zwalidowany DataFrame.</li> </ul>"},{"location":"concepts/validation/#2-_validate_nested_type","title":"2. <code>_validate_nested_type</code>","text":"<p>Sprawdza, czy pojedyncza warto\u015b\u0107 odpowiada oczekiwanemu typowi, obs\u0142uguj\u0105c r\u00f3wnie\u017c zagnie\u017cd\u017cone struktury danych (np. s\u0142owniki i listy). Umo\u017cliwia walidacj\u0119 bardziej z\u0142o\u017conych typ\u00f3w danych.</p>"},{"location":"concepts/validation/#3-_type_to_str","title":"3. <code>_type_to_str</code>","text":"<p>Konwertuje typ lub struktur\u0119 typu na czyteln\u0105 reprezentacj\u0119 w formie string. U\u017cywana przede wszystkim do debugowania i informowania o b\u0142\u0119dach podczas walidacji.</p>"},{"location":"concepts/webhooks/","title":"Webhooks","text":""},{"location":"concepts/webhooks/#wprowadzenie","title":"Wprowadzenie","text":"<p>Webhooki w Data Backbone s\u0142u\u017c\u0105 do aktualizowania zasob\u00f3w i wska\u017anik\u00f3w w odpowiedzi na zdarzenia zachodz\u0105ce w zewn\u0119trznych systemach. Umo\u017cliwiaj\u0105 one automatyczne od\u015bwie\u017canie danych w Data Backbone, gdy nast\u0105pi\u0105 zmiany w zintegrowanych aplikacjach, takich jak Clickup czy Stripe.</p>"},{"location":"concepts/webhooks/#zastosowanie","title":"Zastosowanie","text":"<p>Webhooki s\u0105 u\u017cywane do:</p> <ul> <li>Reagowania na zmiany w innych systemach</li> <li>Automatycznego od\u015bwie\u017cania danych w Data Backbone</li> <li>Synchronizacji danych na podstawie konkretnych zdarze\u0144</li> </ul> <p>Przyk\u0142ady:</p> <ol> <li>Ustawienie automatyzacji w Clickup, kt\u00f3ra wywo\u0142uje webhook w Data Backbone, aby od\u015bwie\u017cy\u0107 dane po okre\u015blonym zdarzeniu.</li> <li>Odbieranie informacji o nowej p\u0142atno\u015bci w Stripe i synchronizacja odpowiednich danych w Data Backbone.</li> </ol>"},{"location":"concepts/webhooks/#konfiguracja","title":"Konfiguracja","text":"<ol> <li>Adres URL webhooka w Data Backbone ma format:</li> </ol> <pre><code>https://twoja-domena.com/webhooks/$nazwa_fn\n</code></pre> <p>gdzie <code>$nazwa_fn</code> to nazwa funkcji webhooka zdefiniowanej w pliku Python.</p> <ol> <li>Na przyk\u0142ad, dla funkcji <code>example_webhook</code>, adres URL b\u0119dzie:    <pre><code>https://twoja-domena.com/webhooks/example_webhook\n</code></pre></li> </ol>"},{"location":"concepts/webhooks/#struktura-webhooka","title":"Struktura Webhooka","text":"<p>Webhook w Data Backbone jest funkcj\u0105 Python o nast\u0119puj\u0105cej strukturze:</p> <pre><code>def example_webhook(mongo_client: MongoClient,\n                    request_body: RequestBody,\n                    request_url_params: RequestUrlParams):\n    # Logika webhooka\n    return { \"request_body\": request_body, \"request_url_params\": request_url_params }\n</code></pre>"},{"location":"concepts/webhooks/#parametry","title":"Parametry:","text":"<ul> <li><code>mongo_client</code>: Instancja MongoClient do interakcji z baz\u0105 danych</li> <li><code>request_body</code>: S\u0142ownik zawieraj\u0105cy dane przes\u0142ane w ciele \u017c\u0105dania</li> <li><code>request_url_params</code>: S\u0142ownik zawieraj\u0105cy parametry URL \u017c\u0105dania</li> </ul>"},{"location":"concepts/webhooks/#typy-danych","title":"Typy danych:","text":"<pre><code>RequestBody = Dict[str, Any]\nRequestUrlParams = Dict[str, Any]\n\nWebhookFunctionType = Callable[\n    [MongoClient, RequestBody, RequestUrlParams],\n    List[Dict[str, Any]]\n]\n</code></pre>"},{"location":"concepts/webhooks/#implementacja-webhooka","title":"Implementacja Webhooka","text":"<p>Aby zaimplementowa\u0107 webhook:</p> <ol> <li>Utw\u00f3rz nowy plik Python w katalogu <code>app/__webhooks__/actions/</code>.</li> <li>Zdefiniuj funkcj\u0119 webhooka zgodnie z powy\u017csz\u0105 struktur\u0105.</li> <li> <p>Zaimplementuj logik\u0119 przetwarzania danych:</p> </li> <li> <p>Pobierz dane z webhooka</p> </li> <li>Dodaj lub zaktualizuj dane w bazie</li> <li> <p>Wykonaj niezb\u0119dne operacje lub zapytania</p> </li> <li> <p>Zwr\u00f3\u0107 wynik w formie s\u0142ownika lub listy s\u0142ownik\u00f3w.</p> </li> </ol>"},{"location":"concepts/webhooks/#przykad","title":"Przyk\u0142ad","text":"<pre><code>def example_webhook(mongo_client: MongoClient,\n                    request_body: RequestBody,\n                    request_url_params: RequestUrlParams):\n\n    # Pobierz dane z webhooka\n    # Przyk\u0142ad: payment_id = request_body.get('payment_id')\n\n    # Dodaj dane do bazy\n    # Przyk\u0142ad: mongo_client['payments'].insert_one({'payment_id': payment_id})\n\n    # Wykonaj inne operacje\n    # Przyk\u0142ad: sync_data(payment_id)\n\n    return { \"request_body\": request_body, \"request_url_params\": request_url_params }\n</code></pre>"},{"location":"concepts/webhooks/#bezpieczenstwo","title":"Bezpiecze\u0144stwo","text":"<ul> <li>Zawsze weryfikuj \u017ar\u00f3d\u0142o przychodz\u0105cych \u017c\u0105da\u0144 webhook.</li> <li>U\u017cywaj szyfrowania HTTPS dla wszystkich po\u0142\u0105cze\u0144 webhook.</li> <li>Rozwa\u017c implementacj\u0119 mechanizmu podpisywania \u017c\u0105da\u0144 dla dodatkowego bezpiecze\u0144stwa.</li> </ul>"},{"location":"concepts/webhooks/#podsumowanie","title":"Podsumowanie","text":"<p>Webhooki w Data Backbone zapewniaj\u0105 elastyczny spos\u00f3b na utrzymanie aktualno\u015bci danych poprzez automatyczne reagowanie na zdarzenia w zewn\u0119trznych systemach. Prawid\u0142owo skonfigurowane i zabezpieczone webhooki mog\u0105 znacznie usprawni\u0107 proces synchronizacji danych i zapewni\u0107, \u017ce twoje analizy zawsze opieraj\u0105 si\u0119 na naj\u015bwie\u017cszych informacjach.</p>"},{"location":"contributing/how-to-contribute/","title":"Jak do\u0142\u0105czy\u0107 do projektu?","text":"<p>Aby do\u0142\u0105czy\u0107 do projektu, prosimy o wys\u0142anie wiadomo\u015bci e-mail na nasz adres licence@databackbone.tech. W tre\u015bci wiadomo\u015bci prosimy o podanie swojego do\u015bwiadczenia oraz obszar\u00f3w, w kt\u00f3rych chcia\u0142by\u015b si\u0119 zaanga\u017cowa\u0107. </p> <p>Mo\u017cliwo\u015bci rozwoju w projekcie s\u0105 niemal nieograniczone, a my z rado\u015bci\u0105 zapraszamy do wsp\u00f3\u0142pracy wszystkich, kt\u00f3rzy chc\u0105 wnie\u015b\u0107 sw\u00f3j wk\u0142ad. Oto kilka obszar\u00f3w, w kt\u00f3rych mo\u017cesz si\u0119 zaanga\u017cowa\u0107:</p> <ul> <li>Integracje z r\u00f3\u017cnymi API: Je\u015bli masz do\u015bwiadczenie w pracy z API, mo\u017cesz pom\u00f3c w tworzeniu nowych integracji, kt\u00f3re rozszerz\u0105 funkcjonalno\u015b\u0107 naszego systemu.</li> <li>Prompty u\u017cytkowe: Tworzenie i optymalizacja prompt\u00f3w, kt\u00f3re u\u0142atwi\u0105 u\u017cytkownikom korzystanie z naszych narz\u0119dzi, to kolejny obszar, w kt\u00f3rym mo\u017cesz si\u0119 wykaza\u0107.</li> <li>Gotowe procesy: Mo\u017cesz pom\u00f3c w projektowaniu i implementacji proces\u00f3w, kt\u00f3re usprawni\u0105 dzia\u0142anie naszego systemu i zwi\u0119ksz\u0105 jego efektywno\u015b\u0107.</li> <li>Architektura: Je\u015bli interesuje Ci\u0119 projektowanie system\u00f3w, mo\u017cesz wnie\u015b\u0107 swoje pomys\u0142y do rozwoju architektury naszego projektu.</li> <li>Twoje w\u0142asne pomys\u0142y: Jeste\u015bmy otwarci na wszelkie innowacyjne pomys\u0142y, kt\u00f3re mog\u0105 przyczyni\u0107 si\u0119 do rozwoju projektu. Je\u015bli masz wizj\u0119, kt\u00f3r\u0105 chcia\u0142by\u015b zrealizowa\u0107, ch\u0119tnie j\u0105 om\u00f3wimy.</li> </ul> <p>Do\u0142\u0105cz do nas i wsp\u00f3lnie rozwijajmy Data Backbone, tworz\u0105c co\u015b wyj\u0105tkowego!</p>"},{"location":"examples/advanced-use-cases/","title":"Zaawansowane przypadki u\u017cycia","text":""},{"location":"examples/advanced-use-cases/#wprowadzenie","title":"Wprowadzenie","text":"<p>W tym rozdziale przedstawimy zaawansowany przypadek u\u017cycia DataBackbone, koncentruj\u0105c si\u0119 na procesie budowania z\u0142o\u017conego wska\u017anika. Jako przyk\u0142ad wykorzystamy funkcj\u0119 <code>build_worklogs_with_cycle_number</code>, kt\u00f3ra tworzy wska\u017anik <code>WorklogsWithCycleNumbers</code>. Ten wska\u017anik \u0142\u0105czy dane z r\u00f3\u017cnych \u017ar\u00f3de\u0142 i przetwarza je w celu uzyskania cennych informacji biznesowych o dziennikach pracy powi\u0105zanych z cyklami rozliczeniowymi.</p>"},{"location":"examples/advanced-use-cases/#budowanie-zozonego-wskaznika","title":"Budowanie z\u0142o\u017conego wska\u017anika","text":""},{"location":"examples/advanced-use-cases/#wskaznik-worklogswithcyclenumbers","title":"Wska\u017anik <code>WorklogsWithCycleNumbers</code>","text":"<p>Wska\u017anik <code>WorklogsWithCycleNumbers</code> dostarcza informacji o dziennikach pracy (worklogs) powi\u0105zanych z cyklami rozliczeniowymi. \u0141\u0105czy on dane z r\u00f3\u017cnych \u017ar\u00f3de\u0142, takich jak faktury, wpisy czasowe i zadania, aby stworzy\u0107 kompleksowy obraz pracy wykonanej w ramach poszczeg\u00f3lnych cykli rozliczeniowych.</p>"},{"location":"examples/advanced-use-cases/#funkcja-budujaca-build_worklogs_with_cycle_number","title":"Funkcja buduj\u0105ca <code>build_worklogs_with_cycle_number</code>","text":"<p>Funkcja <code>build_worklogs_with_cycle_number</code> jest odpowiedzialna za tworzenie wska\u017anika <code>WorklogsWithCycleNumbers</code>.</p>"},{"location":"examples/advanced-use-cases/#uzycie","title":"U\u017cycie","text":"<pre><code>def build_worklogs_with_cycle_number(indicator_setting: Indicator, db_client: MongoClient):\n    # Implementacja funkcji\n    # ...\n    return Validator.validate(final_results, schema_out).to_dict(orient='records')\n</code></pre>"},{"location":"examples/advanced-use-cases/#kluczowe-cechy","title":"Kluczowe cechy","text":"<ul> <li>Pobieranie danych z wielu \u017ar\u00f3de\u0142 (faktury, wpisy czasowe, zadania)</li> <li>Przetwarzanie i \u0142\u0105czenie danych z wykorzystaniem pandas</li> <li>Mapowanie p\u0142atno\u015bci do dziennik\u00f3w pracy</li> <li>Aktualizacja arkuszy Google dla wybranych klient\u00f3w</li> <li>Walidacja wynikowych danych</li> </ul>"},{"location":"examples/advanced-use-cases/#implementacja","title":"Implementacja","text":"<p>Poni\u017cej przedstawiamy kluczowe elementy implementacji:</p> <ol> <li>Pobieranie danych z bazy MongoDB:</li> </ol> <pre><code>stripe_invoices = list(db_client['RESOURCES']['StripeInvoices'].find())\nclickup_time_entries = list(db_client['RESOURCES']['ClickupTimeEntries'].find())\nclickup_tasks = list(db_client['RESOURCES']['ClickupTasks'].find())\nclients = list(db_client['RESOURCES']['ClientMapping'].find())\n</code></pre> <ol> <li>Przetwarzanie danych dla ka\u017cdego klienta:</li> </ol> <pre><code>for client in clients:\n    filtered_invoices = filter_stripe_invoices(stripe_invoices, client['stripe_customer_id'])\n    filtered_time_entries = filter_clickup_entries(clickup_time_entries, client['clickup_folder_id'])\n    filtered_tasks = filter_clickup_tasks(clickup_tasks, int(client['clickup_folder_id']))\n\n    mapped_payments_to_worklogs = map_payments_to_all_worklogs(filtered_time_entries, filtered_invoices, filtered_tasks)\n</code></pre> <ol> <li>Aktualizacja arkuszy Google dla wybranych klient\u00f3w:</li> </ol> <pre><code>if client['company_name'] in project_spreadsheets:\n    logs_with_cycle_number = [\n        {**log, 'cycle_number': cycle['cycle_number']}\n        for cycle in mapped_payments_to_worklogs\n        for log in cycle['log_info']\n    ]\n\n    structure_for_google_sheet = {\n        \"logs_with_cycle_number\": logs_with_cycle_number\n    }\n\n    update_client_google_sheet(client['company_name'], structure_for_google_sheet['logs_with_cycle_number'], worksheet_names['WorklogsWithCycleNumber'])\n</code></pre> <ol> <li>Tworzenie ko\u0144cowego wyniku:</li> </ol> <pre><code>new_row = {\n    'client': client['company_name'],\n    'id': client['company_name'],\n    'date': datetime.now().strftime('%Y-%m-%d'),\n    'mapped_payments_to_worklogs': mapped_payments_to_worklogs\n}\nfinal_results = pd.concat([final_results, pd.DataFrame([new_row])], ignore_index=True)\n</code></pre>"},{"location":"examples/advanced-use-cases/#kluczowe-komponenty","title":"Kluczowe komponenty","text":""},{"location":"examples/advanced-use-cases/#klasa-indicator","title":"Klasa <code>Indicator</code>","text":"<p>Klasa <code>Indicator</code> reprezentuje struktur\u0119 wska\u017anika w DataBackbone. Zawiera informacje takie jak nazwa wska\u017anika, opis i wymagane pola.</p>"},{"location":"examples/advanced-use-cases/#klasa-mongoclient","title":"Klasa <code>MongoClient</code>","text":"<p><code>MongoClient</code> to klasa z biblioteki PyMongo, u\u017cywana do interakcji z baz\u0105 danych MongoDB.</p>"},{"location":"examples/advanced-use-cases/#funkcje-pomocnicze","title":"Funkcje pomocnicze","text":"<ul> <li><code>filter_stripe_invoices()</code>: Filtruje faktury Stripe dla danego klienta.</li> <li><code>filter_clickup_entries()</code>: Filtruje wpisy czasowe ClickUp dla danego folderu.</li> <li><code>filter_clickup_tasks()</code>: Filtruje zadania ClickUp dla danego folderu.</li> <li><code>map_payments_to_all_worklogs()</code>: Mapuje p\u0142atno\u015bci do wszystkich dziennik\u00f3w pracy.</li> <li><code>update_client_google_sheet()</code>: Aktualizuje arkusz Google dla klienta.</li> </ul>"},{"location":"examples/advanced-use-cases/#schemat-wyjsciowy","title":"Schemat wyj\u015bciowy","text":"<p>Schemat wyj\u015bciowy (<code>schema_out</code>) definiuje struktur\u0119 danych wynikowych wska\u017anika <code>WorklogsWithCycleNumbers</code>:</p> <pre><code>schema_out = {\n    \"client\": str,\n    \"id\": str,\n    \"date\": str,\n    \"mapped_payments_to_worklogs\": [\n        {\n            \"cycle_number\": int,\n            \"log_info\": [\n                {\n                    \"date_of_log\": str,\n                    \"worked_time\": float,\n                    \"user_name\": str,\n                    \"task_name\": str,\n                    \"task_id\": str,\n                    \"task_tag_name\": (str, type(None)),\n                    \"description\": str\n                }\n            ]\n        }\n    ]\n}\n</code></pre>"},{"location":"examples/advanced-use-cases/#pena-implementacja","title":"Pe\u0142na implementacja","text":"<pre><code>import pandas as pd\nimport numpy as np\nfrom __indicators__.types import Indicator, MongoClient\nfrom datetime import datetime\nfrom external_services.google.gsheet_utils import update_client_google_sheet\nfrom utils.validator import Validator\nfrom __indicators__.utils.build_worklogs_with_cycle_number import filter_clickup_entries, filter_clickup_tasks, filter_stripe_invoices, find_all_logs_for_cycles\nfrom external_services.client_mappings_details.gsheet_mappings import project_spreadsheets, worksheet_names\n\ndef map_payments_to_all_worklogs(worklogs, invoices, tasks):\n    # Konwertuj listy na DataFrame\n    worklogs_df = pd.DataFrame(worklogs)\n    invoices_df = pd.DataFrame(invoices)\n    tasks_df = pd.DataFrame(tasks)\n\n    # Sortowanie faktur wed\u0142ug daty stworzenia (od najstarszej do najnowszej) i resetowanie indeksu\n    sorted_invoices = invoices_df.sort_values(by='created').reset_index(drop=True)\n\n    # Konwersja kolumny 'created' na datetime\n    sorted_invoices['created'] = pd.to_datetime(sorted_invoices['created'], unit='s')\n\n    # Tworzenie kolumny 'end_of_cycle'\n    sorted_invoices['end_of_cycle'] = sorted_invoices['created'].shift(-1)\n    sorted_invoices.loc[sorted_invoices.index[-1], 'end_of_cycle'] = sorted_invoices['created'].iloc[-1] + pd.Timedelta(days=14)\n\n    # Dodanie kolumny 'cycle_number'\n    sorted_invoices['cycle_number'] = np.arange(1, len(sorted_invoices) + 1)\n\n    # Tworzenie DataFrame mapped_invoices_to_cycles\n    mapped_invoices_to_cycles_df = sorted_invoices[['cycle_number', 'created', 'end_of_cycle']].rename(columns={'created': 'invoice_creation_date_object'})\n\n    # Znalezienie wszystkich dziennik\u00f3w pracy dla cykli\n    mapped_worklogs_to_invoices = find_all_logs_for_cycles(mapped_invoices_to_cycles_df, worklogs_df, tasks_df)\n\n    # Zwr\u00f3\u0107 zmapowane dzienniki pracy do faktur\n    return mapped_worklogs_to_invoices\n\nschema_out = {\n    \"client\": str,\n    \"id\": str,\n    \"date\": str,\n    \"mapped_payments_to_worklogs\": [\n        {\n            \"cycle_number\": int,\n            \"log_info\": [\n                {\n                    \"date_of_log\": str,\n                    \"worked_time\": float,\n                    \"user_name\": str,\n                    \"task_name\": str,\n                    \"task_id\": str,\n                    \"task_tag_name\": (str, type(None)),\n                    \"description\": str\n                }\n            ]\n        }\n    ]\n}\n\n# G\u0142\u00f3wna funkcja przetwarzaj\u0105ca\n\ndef build_worklogs_with_cycle_number(indicator_setting: Indicator, db_client: MongoClient):\n    # Pobierz dane StripeInvoices i ClickupTimeEntries\n    stripe_invoices = list(db_client['RESOURCES']['StripeInvoices'].find())\n    clickup_time_entries = list(db_client['RESOURCES']['ClickupTimeEntries'].find())\n    clickup_tasks = list(db_client['RESOURCES']['ClickupTasks'].find())\n    clients = list(db_client['RESOURCES']['ClientMapping'].find())\n\n    final_results = pd.DataFrame(columns=['client', 'id', 'date', 'mapped_payments_to_worklogs'])\n\n    for client in clients:\n\n        filtered_invoices = filter_stripe_invoices(stripe_invoices, client['stripe_customer_id'])\n        filtered_time_entries = filter_clickup_entries(clickup_time_entries, client['clickup_folder_id'])\n        filtered_tasks = filter_clickup_tasks(clickup_tasks, int(client['clickup_folder_id']))\n\n        mapped_payments_to_worklogs = None\n\n        mapped_payments_to_worklogs = map_payments_to_all_worklogs(filtered_time_entries, filtered_invoices, filtered_tasks)\n\n        if client['company_name'] in project_spreadsheets:\n            # Tworzymy list\u0119 s\u0142ownik\u00f3w bezpo\u015brednio z mapped_payments_to_worklogs\n            logs_with_cycle_number = [\n                {**log, 'cycle_number': cycle['cycle_number']}\n                for cycle in mapped_payments_to_worklogs\n                for log in cycle['log_info']\n            ]\n\n            # Tworzymy nowy s\u0142ownik z przekszta\u0142conymi danymi\n            structure_for_google_sheet = {\n                \"logs_with_cycle_number\": logs_with_cycle_number\n            }\n\n            update_client_google_sheet(client['company_name'],structure_for_google_sheet['logs_with_cycle_number'], worksheet_names['WorklogsWithCycleNumber'])\n        new_row = {\n            'client': client['company_name'],\n            'id': client['company_name'],\n            'date': datetime.now().strftime('%Y-%m-%d'),\n            'mapped_payments_to_worklogs': mapped_payments_to_worklogs\n        }\n        final_results = pd.concat([final_results, pd.DataFrame([new_row])], ignore_index=True)\n\n    return Validator.validate(final_results,schema_out).to_dict(orient='records')\n</code></pre>"},{"location":"examples/advanced-use-cases/#podsumowanie","title":"Podsumowanie","text":"<p>Funkcja <code>build_worklogs_with_cycle_number</code> demonstruje zaawansowane mo\u017cliwo\u015bci DataBackbone w zakresie budowania z\u0142o\u017conych wska\u017anik\u00f3w. Proces tworzenia wska\u017anika <code>WorklogsWithCycleNumbers</code> obejmuje pobieranie danych z bazy MongoDB, filtrowanie i przetwarzanie danych dla ka\u017cdego klienta, mapowanie p\u0142atno\u015bci do dziennik\u00f3w pracy, aktualizacj\u0119 zewn\u0119trznych arkuszy Google oraz tworzenie ko\u0144cowego raportu. Takie podej\u015bcie pozwala na tworzenie kompleksowych wska\u017anik\u00f3w biznesowych, kt\u00f3re mog\u0105 by\u0107 wykorzystywane do analizy i optymalizacji proces\u00f3w w firmie.</p>"},{"location":"examples/basic-examples/","title":"Podstawowe przyk\u0142ady","text":""},{"location":"examples/basic-examples/#wprowadzenie","title":"Wprowadzenie","text":"<p>W tym rozdziale przedstawimy podstawowe przyk\u0142ady pobierania zasobu w DataBackbone, wykorzystuj\u0105c funkcje <code>give_me_resource_from_gsheet</code> oraz <code>give_me_resource_from_webpage</code>. Te przyk\u0142ady demonstruj\u0105, jak pobra\u0107 dane z arkusza Google Sheets oraz ze strony internetowej i przetworzy\u0107 je na format odpowiedni dla DataBackbone.</p>"},{"location":"examples/basic-examples/#pobieranie-zasobu-z-google-sheets","title":"Pobieranie zasobu z Google Sheets","text":""},{"location":"examples/basic-examples/#funkcja-give_me_resource_from_gsheet","title":"Funkcja <code>give_me_resource_from_gsheet</code>","text":"<p>Funkcja <code>give_me_resource_from_gsheet</code> s\u0142u\u017cy do pobierania danych z arkusza Google Sheets i przetwarzania ich na format zasobu DataBackbone.</p>"},{"location":"examples/basic-examples/#uzycie","title":"U\u017cycie","text":"<pre><code>def give_me_resource_from_gsheet(resource_setting: Resource, mongo_client: MongoClient):\n    # Implementacja funkcji\n    # ...\n    return data\n</code></pre>"},{"location":"examples/basic-examples/#kluczowe-cechy","title":"Kluczowe cechy","text":"<ul> <li>Autoryzacja dost\u0119pu do Google Sheets i Google Drive</li> <li>Sprawdzanie istnienia arkusza i worksheet</li> <li>Pobieranie danych z arkusza</li> <li>Przetwarzanie danych do formatu zasobu DataBackbone</li> </ul>"},{"location":"examples/basic-examples/#implementacja","title":"Implementacja","text":"<p>Poni\u017cej przedstawiamy kluczowe elementy implementacji:</p> <ol> <li>Autoryzacja:</li> </ol> <pre><code>gsheets, _ = authorize_gspread_gdrive()\n</code></pre> <ol> <li>Sprawdzanie istnienia arkusza i worksheet:</li> </ol> <pre><code>spreadsheet = sheet_exist(gsheets, spreadsheet_id)\nworksheet = worksheet_exists(gsheets, spreadsheet, worksheet_name)\n</code></pre> <ol> <li>Pobieranie i przetwarzanie danych:</li> </ol> <pre><code>vals = worksheet.get_all_values()\nkeys = vals[0]\nvals = vals[1:]\n\ndata = []\nfor idx, entry in enumerate(vals):\n    item = {}\n    for key_idx, key in enumerate(keys):\n        item[key] = entry[key_idx]\n    data.append(item)\n</code></pre>"},{"location":"examples/basic-examples/#pena-implementacja-funkcji","title":"Pe\u0142na implementacja funkcji","text":"<pre><code>from external_services.google.google import authorize_gspread_gdrive\nfrom external_services.google.gsheet_utils import sheet_exist, worksheet_exists\nfrom __resources__.types import Resource, MongoClient\n\ndef give_me_resource_from_gsheet(resource_setting: Resource, mongo_client: MongoClient):\n    # Autoryzacja dost\u0119pu do Google Sheets i Google Drive\n    gsheets, _ = authorize_gspread_gdrive()\n\n    # ID arkusza Google Sheets\n    spreadsheet_id = '1O4afNBV9pJdDjXmk0EGitKdDIzInjDNylgmQf6oHNKM'\n    # Nazwa worksheet w arkuszu\n    worksheet_name = '(AUTO) ExampleSheet'\n\n    # Sprawdzenie czy arkusz istnieje\n    spreadsheet = sheet_exist(gsheets, spreadsheet_id)\n    if not spreadsheet:\n        raise Exception(f\"Google Sheet o id: {spreadsheet_id} nie istnieje\")\n\n    # Sprawdzenie czy worksheet istnieje w arkuszu\n    worksheet = worksheet_exists(gsheets, spreadsheet, worksheet_name)\n\n    # Pobranie wszystkich warto\u015bci z worksheet\n    vals = worksheet.get_all_values()\n\n    # Pierwszy wiersz jako klucze (nag\u0142\u00f3wki kolumn)\n    keys = vals[0]\n    # Pozosta\u0142e wiersze jako dane\n    vals = vals[1:]\n\n    # Lista na przetworzone dane\n    data = []\n\n    # Iteracja przez ka\u017cdy wiersz danych\n    for idx, entry in enumerate(vals):\n        item = {}\n        # Mapowanie kluczy i warto\u015bci\n        for key_idx, key in enumerate(keys):\n            item[key] = entry[key_idx]\n        # Dodanie przetworzonego wiersza do listy danych\n        data.append(item)\n\n    # Zwr\u00f3cenie przetworzonych danych\n    return data\n</code></pre>"},{"location":"examples/basic-examples/#pobieranie-zasobu-ze-strony-internetowej","title":"Pobieranie zasobu ze strony internetowej","text":""},{"location":"examples/basic-examples/#funkcja-give_me_resource_from_webpage","title":"Funkcja <code>give_me_resource_from_webpage</code>","text":"<p>Funkcja <code>give_me_resource_from_webpage</code> s\u0142u\u017cy do pobierania danych z okre\u015blonej strony internetowej i przetwarzania ich na format zasobu DataBackbone.</p>"},{"location":"examples/basic-examples/#uzycie_1","title":"U\u017cycie","text":"<pre><code>async def give_me_resource_from_webpage(resource_setting: Resource, mongo_client: MongoClient):\n    # Implementacja funkcji\n    # ...\n    return rows\n</code></pre>"},{"location":"examples/basic-examples/#kluczowe-cechy_1","title":"Kluczowe cechy","text":"<ul> <li>Asynchroniczne pobieranie danych ze strony internetowej</li> <li>Wykorzystanie Playwright do renderowania strony</li> <li>Parsowanie HTML za pomoc\u0105 BeautifulSoup</li> <li>Ekstrakcja danych z tabeli HTML</li> </ul>"},{"location":"examples/basic-examples/#implementacja_1","title":"Implementacja","text":"<p>Poni\u017cej przedstawiamy kluczowe elementy implementacji:</p> <ol> <li>Uruchomienie przegl\u0105darki i nawigacja do strony:</li> </ol> <pre><code>async with async_playwright() as p:\n    browser = await p.chromium.launch(headless=False)\n    page = await browser.new_page()\n    await page.goto('https://hook.eu2.make.com/q07viqfnlysxe9z267tc2vwl2548luxq')\n</code></pre> <ol> <li>Pobieranie zawarto\u015bci tabeli:</li> </ol> <pre><code>await page.wait_for_selector('div#table')\ntable_html = await page.inner_html('div#table')\n</code></pre> <ol> <li>Parsowanie HTML i ekstrakcja danych:</li> </ol> <pre><code>soup = BeautifulSoup(table_html, 'html.parser')\ntable = soup.find('table')\nheaders = [th.get_text(strip=True) for th in table.find_all('th')]\nrows = []\nfor tr in table.find_all('tr'):\n    cells = tr.find_all(['td', 'th'])\n    if len(cells) != len(headers):\n        continue\n    row = {headers[ix]: cell.get_text(strip=True) for ix, cell in enumerate(cells)}\n    rows.append(row)\n</code></pre>"},{"location":"examples/basic-examples/#kluczowe-komponenty","title":"Kluczowe komponenty","text":""},{"location":"examples/basic-examples/#klasa-resource","title":"Klasa <code>Resource</code>","text":"<p>Klasa <code>Resource</code> reprezentuje struktur\u0119 zasobu w DataBackbone. Zawiera informacje takie jak nazwa zasobu, opis, dzia\u0142 i wymagane pola.</p>"},{"location":"examples/basic-examples/#klasa-mongoclient","title":"Klasa <code>MongoClient</code>","text":"<p><code>MongoClient</code> to klasa z biblioteki PyMongo, u\u017cywana do interakcji z baz\u0105 danych MongoDB.</p>"},{"location":"examples/basic-examples/#biblioteki-zewnetrzne","title":"Biblioteki zewn\u0119trzne","text":"<ul> <li><code>gspread</code>: U\u017cywana do interakcji z Google Sheets API.</li> <li><code>playwright</code>: U\u017cywana do renderowania stron internetowych i interakcji z nimi.</li> <li><code>BeautifulSoup</code>: U\u017cywana do parsowania HTML i ekstrakcji danych.</li> </ul>"},{"location":"examples/basic-examples/#pena-implementacja-funkcji_1","title":"Pe\u0142na implementacja funkcji","text":"<pre><code>from __resources__.types import Resource, MongoClient\nfrom playwright.async_api import async_playwright\nfrom bs4 import BeautifulSoup\n\nasync def give_me_resource_from_webpage(resource_setting: Resource, mongo_client: MongoClient):\n    # Rozpocznij asynchroniczne korzystanie z playwright\n    async with async_playwright() as p:\n        # Uruchom przegl\u0105dark\u0119 w trybie z widocznym interfejsem\n        browser = await p.chromium.launch(headless=False)\n        # Utw\u00f3rz now\u0105 kart\u0119 przegl\u0105darki\n        page = await browser.new_page()\n\n        # Przejd\u017a do \u017c\u0105danej strony\n        await page.goto('https://hook.eu2.make.com/q07viqfnlysxe9z267tc2vwl2548luxq')\n\n        # Czekaj, a\u017c element div z id 'table' b\u0119dzie dost\u0119pny na stronie\n        await page.wait_for_selector('div#table')\n\n        # Pobierz zawarto\u015b\u0107 tabeli jako HTML\n        table_html = await page.inner_html('div#table')\n\n        # Zamknij przegl\u0105dark\u0119\n        await browser.close()\n\n        # Wgraj zawarto\u015b\u0107 tabeli do BeautifulSoup\n        soup = BeautifulSoup(table_html, 'html.parser')\n\n        # Znajd\u017a tabel\u0119 w HTML\n        table = soup.find('table')\n        if not table:\n            raise ValueError(\"No table found in the provided HTML.\")\n\n        # Pobierz wszystkie nag\u0142\u00f3wki kolumn\n        headers = [th.get_text(strip=True) for th in table.find_all('th')]\n\n        # Pobierz wszystkie warto\u015bci wierszy\n        rows = []\n        for tr in table.find_all('tr'):\n            # Znajd\u017a wszystkie kom\u00f3rki w wierszu\n            cells = tr.find_all(['td', 'th'])\n            # Pomijaj wiersze, kt\u00f3re nie maj\u0105 takiej samej liczby kom\u00f3rek jak nag\u0142\u00f3wki\n            if len(cells) != len(headers):\n                continue\n            # Utw\u00f3rz s\u0142ownik dla wiersza, \u0142\u0105cz\u0105c nag\u0142\u00f3wki z odpowiednimi warto\u015bciami kom\u00f3rek\n            row = {headers[ix]: cell.get_text(strip=True) for ix, cell in enumerate(cells)}\n            rows.append(row)\n\n        return rows\n</code></pre>"},{"location":"examples/basic-examples/#podsumowanie","title":"Podsumowanie","text":"<p>Przyk\u0142ady <code>give_me_resource_from_gsheet</code> i <code>give_me_resource_from_webpage</code> demonstruj\u0105, jak DataBackbone mo\u017ce pobiera\u0107 dane z r\u00f3\u017cnych zewn\u0119trznych \u017ar\u00f3de\u0142 (Google Sheets i strony internetowe) i przetwarza\u0107 je na format zasobu. Procesy te obejmuj\u0105 autoryzacj\u0119 (w przypadku Google Sheets), pobieranie danych, parsowanie i przetwarzanie. Takie podej\u015bcie pozwala na elastyczne integrowanie r\u00f3\u017cnych \u017ar\u00f3de\u0142 danych z systemem DataBackbone.</p>"},{"location":"getting-started/development-installation/","title":"Instalacja \u015brodowiska developerskiego","text":""},{"location":"getting-started/development-installation/#wprowadzenie","title":"Wprowadzenie","text":"<p>Data Backbone oferuje dwie metody instalacji \u015brodowiska developerskiego: z u\u017cyciem Docker Compose oraz z wykorzystaniem wirtualnego \u015brodowiska Python (venv). Obie metody zapewniaj\u0105 kompletne \u015brodowisko do pracy z Data Backbone.</p>"},{"location":"getting-started/development-installation/#instalacja-z-uzyciem-docker-compose","title":"Instalacja z u\u017cyciem Docker Compose","text":""},{"location":"getting-started/development-installation/#wymagania-wstepne","title":"Wymagania wst\u0119pne","text":"<ul> <li>Zainstalowany Docker</li> <li>Zainstalowany Docker Compose</li> </ul>"},{"location":"getting-started/development-installation/#kroki-instalacji","title":"Kroki instalacji","text":""},{"location":"getting-started/development-installation/#1-sklonuj-repozytorium-data-backbone","title":"1. Sklonuj repozytorium Data Backbone:","text":"<pre><code>git clone https://github.com/twoja-organizacja/data-backbone.git\ncd data-backbone\n</code></pre>"},{"location":"getting-started/development-installation/#2-uruchom-srodowisko-za-pomoca-docker-compose","title":"2. Uruchom \u015brodowisko za pomoc\u0105 Docker Compose:","text":"<pre><code>docker-compose up -d\n</code></pre>"},{"location":"getting-started/development-installation/#3-po-zakonczeniu-procesu-srodowisko-developerskie-bedzie-dostepne-pod-nastepujacymi-adresami","title":"3. Po zako\u0144czeniu procesu, \u015brodowisko developerskie b\u0119dzie dost\u0119pne pod nast\u0119puj\u0105cymi adresami:","text":"<ul> <li>Aplikacja g\u0142\u00f3wna: <code>http://localhost:8000</code></li> <li>Panel administracyjny MongoDB: <code>http://localhost:8081</code></li> <li>\u015arodowisko VS Code: <code>http://localhost:3991</code> (has\u0142o: <code>PSWD</code>)</li> </ul>"},{"location":"getting-started/development-installation/#instalacja-z-uzyciem-wirtualnego-srodowiska-python-venv","title":"Instalacja z u\u017cyciem wirtualnego \u015brodowiska Python (venv)","text":""},{"location":"getting-started/development-installation/#wymagania-wstepne_1","title":"Wymagania wst\u0119pne","text":"<ul> <li>Python 3.8 lub nowszy</li> <li>pip (mened\u017cer pakiet\u00f3w Python)</li> <li>Docker (dla baz danych)</li> </ul>"},{"location":"getting-started/development-installation/#kroki-instalacji_1","title":"Kroki instalacji","text":""},{"location":"getting-started/development-installation/#1-sklonuj-repozytorium-data-backbone_1","title":"1. Sklonuj repozytorium Data Backbone:","text":"<pre><code>git clone https://github.com/twoja-organizacja/data-backbone.git\ncd data-backbone\n</code></pre>"},{"location":"getting-started/development-installation/#2-utworz-i-aktywuj-wirtualne-srodowisko-python","title":"2. Utw\u00f3rz i aktywuj wirtualne \u015brodowisko Python:","text":"<pre><code>python -m venv venv\nsource venv/bin/activate # Na Windows u\u017cyj: venv\\Scripts\\activate\n</code></pre>"},{"location":"getting-started/development-installation/#3-zainstaluj-wymagane-zaleznosci","title":"3. Zainstaluj wymagane zale\u017cno\u015bci:","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/development-installation/#4-uruchom-bazy-danych-za-pomoca-docker-compose","title":"4. Uruchom bazy danych za pomoc\u0105 Docker Compose:","text":"<pre><code>docker-compose up -d mongo weaviate mongo-admin\n</code></pre>"},{"location":"getting-started/development-installation/#5-uruchom-aplikacje-data-backbone","title":"5. Uruchom aplikacj\u0119 Data Backbone:","text":"<pre><code>python app/main.py\n</code></pre>"},{"location":"getting-started/development-installation/#6-po-zakonczeniu-procesu-srodowisko-developerskie-bedzie-dostepne-pod-nastepujacymi-adresami","title":"6. Po zako\u0144czeniu procesu, \u015brodowisko developerskie b\u0119dzie dost\u0119pne pod nast\u0119puj\u0105cymi adresami:","text":"<ul> <li>Aplikacja g\u0142\u00f3wna: <code>http://localhost:8000</code></li> <li>Panel administracyjny MongoDB: <code>http://localhost:8081</code></li> </ul>"},{"location":"getting-started/development-installation/#konfiguracja-srodowiska","title":"Konfiguracja \u015brodowiska","text":"<p>Niezale\u017cnie od wybranej metody instalacji, konieczne jest utworzenie pliku <code>.env</code> w folderze <code>/app</code> i skonfigurowanie w nim niezb\u0119dnych zmiennych \u015brodowiskowych.</p>"},{"location":"getting-started/development-installation/#weryfikacja-instalacji","title":"Weryfikacja instalacji","text":"<p>Aby zweryfikowa\u0107 poprawno\u015b\u0107 instalacji, wykonaj nast\u0119puj\u0105ce kroki:</p> <ol> <li> <p>Otw\u00f3rz przegl\u0105dark\u0119 i przejd\u017a do <code>http://localhost:8000/dev_app</code></p> </li> <li> <p>Powiniene\u015b zobaczy\u0107 stron\u0119 powitaln\u0105 Data Backbone</p> </li> <li> <p>Spr\u00f3buj zalogowa\u0107 si\u0119 do panelu administracyjnego MongoDB pod adresem <code>http://localhost:8081</code></p> </li> </ol>"},{"location":"getting-started/development-installation/#rozwiazywanie-problemow","title":"Rozwi\u0105zywanie problem\u00f3w","text":"<p>Je\u015bli napotkasz problemy podczas instalacji lub uruchamiania \u015brodowiska, sprawd\u017a nast\u0119puj\u0105ce rzeczy:</p> <ol> <li> <p>Upewnij si\u0119, \u017ce wszystkie wymagane porty s\u0105 wolne (8000, 8081, 3991, 27017)</p> </li> <li> <p>Sprawd\u017a logi Docker Compose, u\u017cywaj\u0105c polecenia <code>docker-compose logs</code></p> </li> <li> <p>Upewnij si\u0119, \u017ce wszystkie wymagane zmienne \u015brodowiskowe s\u0105 poprawnie ustawione w pliku <code>.env</code></p> </li> </ol>"},{"location":"getting-started/development-installation/#podsumowanie","title":"Podsumowanie","text":"<p>Teraz masz gotowe \u015brodowisko developerskie Data Backbone. Mo\u017cesz rozpocz\u0105\u0107 prac\u0119 nad rozwojem i dostosowywaniem systemu do swoich potrzeb. Pami\u0119taj, \u017ce w przypadku problem\u00f3w zawsze mo\u017cesz skorzysta\u0107 z dokumentacji lub zwr\u00f3ci\u0107 si\u0119 o pomoc do zespo\u0142u wsparcia Data Backbone.</p>"},{"location":"getting-started/env-description/","title":"Opis \u015brodowiska","text":""},{"location":"getting-started/env-description/#wprowadzenie","title":"Wprowadzenie","text":"<p>Data Backbone wykorzystuje Docker do zarz\u0105dzania \u015brodowiskiem deweloperskim i produkcyjnym. Plik <code>docker-compose.yaml</code> definiuje wszystkie niezb\u0119dne us\u0142ugi i ich konfiguracje. Poni\u017cej znajduje si\u0119 szczeg\u00f3\u0142owy opis ka\u017cdej us\u0142ugi i jej roli w systemie.</p>"},{"location":"getting-started/env-description/#struktura-docker-compose","title":"Struktura docker-compose","text":""},{"location":"getting-started/env-description/#volumes","title":"Volumes","text":"<p>Zdefiniowane s\u0105 nast\u0119puj\u0105ce woluminy:</p> <ul> <li><code>hd_shared</code>: Wsp\u00f3\u0142dzielony wolumin dla danych aplikacji.</li> </ul>"},{"location":"getting-started/env-description/#services","title":"Services","text":""},{"location":"getting-started/env-description/#vscode","title":"vscode","text":"<p>Us\u0142uga <code>vscode</code> zapewnia \u015brodowisko programistyczne dost\u0119pne przez przegl\u0105dark\u0119.</p> <pre><code>vscode:\n  container_name: vscode\n  image: codercom/code-server:latest\n  ports:\n    - '3991:8080'\n  volumes:\n    - hd_shared:/home/coder/project:rw\n    - /var/run/docker.sock:/var/run/docker.sock\n  environment:\n    - 'PASSWORD=PSWD'\n    - 'DOCKER_USER=$USER'\n  user: '0:0'\n  depends_on:\n    - server\n  networks:\n    - external\n</code></pre> <ul> <li>Port <code>3991</code> jest mapowany na port <code>8080</code> kontenera.</li> <li>Wsp\u00f3\u0142dzielony wolumin <code>hd_shared</code> jest montowany w <code>/home/coder/project</code>.</li> <li>Us\u0142uga wymaga uruchomienia us\u0142ugi <code>server</code>.</li> </ul>"},{"location":"getting-started/env-description/#server","title":"server","text":"<p>Us\u0142uga <code>server</code> to g\u0142\u00f3wna aplikacja Data Backbone.</p> <pre><code>server:\n  build:\n    context: .\n    dockerfile: ./app.Dockerfile\n  env_file:\n    - ./app/.env\n  ports:\n    - '8000:8000'\n  volumes:\n    - hd_shared:/app\n  environment:\n    MONGO_URI: ${MONGO_URI}\n    WEAVIATE_URL: weaviate\n    TOKEN: ${TOKEN}\n    CORS_ORIGIN: '${CORS_ORIGIN}'\n    OPENAI_KEY: ${OPENAI_KEY}\n    STRIPE_KEY: ${STRIPE_KEY}\n    CLICKUP_KEY: ${CLICKUP_KEY}\n    FAKTUROWNIA_TOKEN: ${FAKTUROWNIA_TOKEN}\n  depends_on:\n    - mongo\n    - mongo-admin\n    - weaviate\n</code></pre> <ul> <li>Port <code>8000</code> jest mapowany na port <code>8000</code> kontenera.</li> <li>Wsp\u00f3\u0142dzielony wolumin <code>hd_shared</code> jest montowany w <code>/app</code>.</li> <li>Us\u0142uga wymaga uruchomienia us\u0142ug <code>mongo</code>, <code>mongo-admin</code> i <code>weaviate</code>.</li> </ul>"},{"location":"getting-started/env-description/#weaviate","title":"weaviate","text":"<p>Us\u0142uga <code>weaviate</code> to baza danych wektorowa u\u017cywana w systemie.</p> <pre><code>weaviate:\n  image: cr.weaviate.io/semitechnologies/weaviate:latest\n  restart: on-failure:0\n  logging:\n    driver: 'none'\n  ports:\n    - '8080:8080'\n    - '50051:50051'\n  environment:\n    LOG_LEVEL: 'debug'\n    QUERY_DEFAULTS_LIMIT: 1000\n    ASYNC_INDEXING: 'true'\n    AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n    DEFAULT_VECTORIZER_MODULE: 'text2vec-openai'\n    ENABLE_MODULES: 'text2vec-openai'\n    PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n    CLUSTER_HOSTNAME: 'node1'\n</code></pre> <ul> <li>Porty <code>8080</code> i <code>50051</code> s\u0105 mapowane na te same porty kontenera.</li> <li>Us\u0142uga jest skonfigurowana do u\u017cywania modu\u0142u <code>text2vec-openai</code>.</li> </ul>"},{"location":"getting-started/env-description/#mongo","title":"mongo","text":"<p>Us\u0142uga <code>mongo</code> to baza danych MongoDB u\u017cywana w systemie.</p> <pre><code>mongo:\n  image: mongo:4.4\n  ports:\n    - '27017:27017'\n  logging:\n    driver: 'none'\n  environment:\n    MONGO_INITDB_ROOT_USERNAME: root\n    MONGO_INITDB_ROOT_PASSWORD: example\n</code></pre> <ul> <li>Port <code>27017</code> jest mapowany na port <code>27017</code> kontenera.</li> </ul>"},{"location":"getting-started/env-description/#mongo-admin","title":"mongo-admin","text":"<p>Us\u0142uga <code>mongo-admin</code> to interfejs administracyjny dla MongoDB.</p> <pre><code>mongo-admin:\n  image: mongo-express:latest\n  ports:\n    - '8081:8081'\n  logging:\n    driver: 'none'\n  depends_on:\n    - mongo\n  environment:\n    ME_CONFIG_MONGODB_ADMINUSERNAME: root\n    ME_CONFIG_MONGODB_ADMINPASSWORD: example\n    ME_CONFIG_MONGODB_URL: mongodb://root:example@mongo:27017/\n</code></pre> <ul> <li>Port <code>8081</code> jest mapowany na port <code>8081</code> kontenera.</li> <li>Us\u0142uga wymaga uruchomienia us\u0142ugi <code>mongo</code>.</li> </ul>"},{"location":"getting-started/env-description/#podsumowanie","title":"Podsumowanie","text":"<p>Plik <code>docker-compose.yaml</code> definiuje kompletne \u015brodowisko dla Data Backbone, zawieraj\u0105ce wszystkie niezb\u0119dne us\u0142ugi: serwer aplikacji, baz\u0119 danych MongoDB, baz\u0119 danych wektorow\u0105 Weaviate oraz narz\u0119dzia deweloperskie. Dzi\u0119ki tej konfiguracji mo\u017cesz \u0142atwo uruchomi\u0107 ca\u0142y system jednym poleceniem, co znacznie upraszcza proces rozwoju i wdra\u017cania aplikacji.</p>"},{"location":"getting-started/production-installation/","title":"Instalacja \u015brodowiska produkcyjnego","text":""},{"location":"getting-started/production-installation/#wprowadzenie","title":"Wprowadzenie","text":"<p>Data Backbone oferuje pe\u0142ne \u015brodowisko produkcyjne oparte na Docker Compose. Ta metoda zapewnia \u0142atwe wdro\u017cenie i zarz\u0105dzanie wszystkimi komponentami systemu w \u015brodowisku produkcyjnym.</p>"},{"location":"getting-started/production-installation/#wymagania-wstepne","title":"Wymagania wst\u0119pne","text":"<ul> <li>Zainstalowany Docker</li> <li>Zainstalowany Docker Compose</li> <li>Serwer z systemem Linux (zalecany Ubuntu 20.04 LTS lub nowszy)</li> <li>Minimum 4 GB RAM i 20 GB przestrzeni dyskowej</li> </ul>"},{"location":"getting-started/production-installation/#kroki-instalacji","title":"Kroki instalacji","text":""},{"location":"getting-started/production-installation/#1-przygotowanie-serwera","title":"1. Przygotowanie serwera","text":"<p>Zaktualizuj system i zainstaluj niezb\u0119dne narz\u0119dzia:</p> <pre><code>sudo apt update &amp;&amp; sudo apt upgrade -y\nsudo apt install -y git curl\n</code></pre>"},{"location":"getting-started/production-installation/#2-instalacja-docker-i-docker-compose","title":"2. Instalacja Docker i Docker Compose","text":"<p>Istniej\u0105 dwie metody instalacji Docker i Docker Compose: poprzez konsol\u0119 lub pobieraj\u0105c instalatory ze strony internetowej.</p>"},{"location":"getting-started/production-installation/#metoda-1-instalacja-przez-konsole","title":"Metoda 1: Instalacja przez konsol\u0119","text":"<p>Zainstaluj Docker:</p> <pre><code>curl -fsSL https://get.docker.com -o get-docker.sh\nsudo sh get-docker.sh\nsudo usermod -aG docker $USER\n</code></pre> <p>Zainstaluj Docker Compose:</p> <pre><code>sudo curl -L \"https://github.com/docker/compose/releases/download/1.29.2/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose\nsudo chmod +x /usr/local/bin/docker-compose\n</code></pre>"},{"location":"getting-started/production-installation/#metoda-2-instalacja-poprzez-pobranie-ze-strony","title":"Metoda 2: Instalacja poprzez pobranie ze strony","text":"<ol> <li>Przejd\u017a na oficjaln\u0105 stron\u0119 Docker: https://www.docker.com/products/docker-desktop</li> <li>Pobierz instalator odpowiedni dla Twojego systemu operacyjnego (Windows, macOS lub Linux).</li> <li>Uruchom pobrany instalator i post\u0119puj zgodnie z instrukcjami na ekranie.</li> <li>Po zainstalowaniu Docker Desktop, Docker Compose b\u0119dzie ju\u017c dost\u0119pny w systemie.</li> </ol> <p>Po zako\u0144czeniu instalacji, niezale\u017cnie od wybranej metody, zweryfikuj poprawno\u015b\u0107 instalacji, wykonuj\u0105c w terminalu nast\u0119puj\u0105ce polecenia:</p> <pre><code>docker --version\ndocker-compose --version\n</code></pre> <p>Je\u015bli instalacja przebieg\u0142a pomy\u015blnie, powiniene\u015b zobaczy\u0107 numery wersji zainstalowanych narz\u0119dzi.</p>"},{"location":"getting-started/production-installation/#3-pobranie-repozytorium-data-backbone","title":"3. Pobranie repozytorium Data Backbone","text":"<p>Sklonuj repozytorium Data Backbone:</p> <pre><code>git clone https://github.com/twoja-organizacja/data-backbone.git\ncd data-backbone\n</code></pre>"},{"location":"getting-started/production-installation/#4-konfiguracja-srodowiska","title":"4. Konfiguracja \u015brodowiska","text":"<p>Utw\u00f3rz plik <code>.env</code> w katalogu <code>/app</code> i skonfiguruj w nim niezb\u0119dne zmienne \u015brodowiskowe:</p> <p>Dostosuj warto\u015bci zmiennych do swojego \u015brodowiska produkcyjnego.</p>"},{"location":"getting-started/production-installation/#5-uruchomienie-srodowiska","title":"5. Uruchomienie \u015brodowiska","text":"<p>Uruchom \u015brodowisko za pomoc\u0105 Docker Compose:</p> <pre><code>docker-compose up -d\n</code></pre>"},{"location":"getting-started/production-installation/#podsumowanie","title":"Podsumowanie","text":"<p>Teraz masz gotowe produkcyjne \u015brodowisko Data Backbone. Pami\u0119taj o regularnym monitorowaniu, aktualizacjach i tworzeniu kopii zapasowych. W przypadku problem\u00f3w, zawsze mo\u017cesz skorzysta\u0107 z dokumentacji lub zwr\u00f3ci\u0107 si\u0119 o pomoc do zespo\u0142u wsparcia Data Backbone.</p>"},{"location":"getting-started/requirements/","title":"Wymagane umiej\u0119tno\u015bci","text":""},{"location":"getting-started/requirements/#wymagane-umiejetnosci-do-obsugi-data-backbone","title":"Wymagane umiej\u0119tno\u015bci do obs\u0142ugi Data Backbone","text":"<p>Aby efektywnie korzysta\u0107 z Data Backbone, zaleca si\u0119 posiadanie nast\u0119puj\u0105cych umiej\u0119tno\u015bci:</p>"},{"location":"getting-started/requirements/#podstawowe-umiejetnosci-techniczne","title":"Podstawowe umiej\u0119tno\u015bci techniczne","text":"<ul> <li>Znajomo\u015b\u0107 technologii: Umiej\u0119tno\u015b\u0107 poruszania si\u0119 w \u015brodowisku technologicznym oraz zrozumienie podstawowych poj\u0119\u0107 zwi\u0105zanych z IT.</li> <li>Programowanie w Pythonie: Bieg\u0142o\u015b\u0107 w j\u0119zyku Python, w tym znajomo\u015b\u0107 bibliotek takich jak pandas, numpy, fastapi oraz request.</li> </ul>"},{"location":"getting-started/requirements/#umiejetnosci-zwiazane-z-ai","title":"Umiej\u0119tno\u015bci zwi\u0105zane z AI","text":"<ul> <li>Interakcja z AI: Zdolno\u015b\u0107 do pracy z r\u00f3\u017cnymi koncepcjami zwi\u0105zanymi ze sztuczn\u0105 inteligencj\u0105, w tym zrozumienie jej mo\u017cliwo\u015bci i ogranicze\u0144.</li> <li>Umiej\u0119tno\u015b\u0107 promptowania: Tworzenie skutecznych zapyta\u0144 i polece\u0144 dla modeli AI w celu uzyskania po\u017c\u0105danych rezultat\u00f3w.</li> </ul>"},{"location":"getting-started/requirements/#umiejetnosci-analityczne","title":"Umiej\u0119tno\u015bci analityczne","text":"<ul> <li>Krytyczne my\u015blenie: Zdolno\u015b\u0107 do analizy i oceny informacji w celu podejmowania \u015bwiadomych decyzji.</li> <li>Rozwi\u0105zywanie problem\u00f3w: Umiej\u0119tno\u015b\u0107 identyfikacji problem\u00f3w oraz opracowywania skutecznych rozwi\u0105za\u0144.</li> </ul>"},{"location":"getting-started/requirements/#umiejetnosci-komunikacyjne","title":"Umiej\u0119tno\u015bci komunikacyjne","text":"<ul> <li>Czytanie ze zrozumieniem: Zdolno\u015b\u0107 do efektywnego przyswajania i interpretacji dokumentacji technicznej oraz innych materia\u0142\u00f3w pisemnych.</li> </ul>"},{"location":"getting-started/requirements/#wymagania-dla-modego-programisty-korzystajacego-z-ai","title":"Wymagania dla m\u0142odego programisty korzystaj\u0105cego z AI","text":"<ul> <li>Nauka Pythona i promptowania: Daj m\u0142odemu programi\u015bcie dowolnego j\u0119zyka kilkaka\u015bcie dni na opanowanie podstaw j\u0119zyka Python oraz umiej\u0119tno\u015bci tworzenia skutecznych prompt\u00f3w dla modeli AI</li> <li>Zrozumienie dzia\u0142ania Data Backbone: Przeznacz jeszcze tydzie\u0144 na nauk\u0119 i zrozumienie, jak dzia\u0142a Data Backbone, aby m\u00f3g\u0142 efektywnie korzysta\u0107 z jego funkcji</li> </ul>"},{"location":"licencing/commercial-licence/","title":"Licencja komercyjna","text":""},{"location":"licencing/commercial-licence/#dla-kogo","title":"Dla kogo:","text":"<p>Nasza licencja komercyjna jest idealna dla firm, kt\u00f3re pragn\u0105 rozszerzy\u0107 swoje mo\u017cliwo\u015bci w zakresie analizy danych i raportowania. Skierowana jest do przedsi\u0119biorstw, kt\u00f3re chc\u0105 zyska\u0107 przewag\u0119 konkurencyjn\u0105 poprzez zaawansowane narz\u0119dzia analityczne.</p>"},{"location":"licencing/commercial-licence/#profile-firm","title":"Profile firm:","text":"<ul> <li> <p>Firmy \u015bwiadcz\u0105ce us\u0142ugi finansowe w sektorze M\u015aP: Nasza licencja jest idealna dla firm, kt\u00f3re oferuj\u0105 us\u0142ugi finansowe dla ma\u0142ych i \u015brednich przedsi\u0119biorstw. Dzi\u0119ki Data Backbone, te firmy mog\u0105 lepiej zrozumie\u0107 potrzeby swoich klient\u00f3w, optymalizowa\u0107 swoje us\u0142ugi oraz zwi\u0119ksza\u0107 swoj\u0105 konkurencyjno\u015b\u0107 na rynku.  </p> </li> <li> <p>Firmy z us\u0142ugami ksi\u0119gowymi i CFO: Nasze rozwi\u0105zania s\u0105 doskona\u0142e dla firm, kt\u00f3re potrzebuj\u0105 precyzyjnych narz\u0119dzi do analizy finansowej, planowania bud\u017cetowego oraz raportowania. Dzi\u0119ki naszej licencji, firmy te mog\u0105 usprawni\u0107 swoje procesy ksi\u0119gowe i zarz\u0105dcze, co pozwala na lepsze zarz\u0105dzanie finansami.</p> </li> <li> <p>Firmy zapewniaj\u0105ce support analityczny i raportowanie na podstawie danych: Dla firm, kt\u00f3re specjalizuj\u0105 si\u0119 w dostarczaniu us\u0142ug analitycznych, nasza licencja oferuje zaawansowane narz\u0119dzia do przetwarzania i analizy danych. Umo\u017cliwia to tworzenie dok\u0142adnych i szczeg\u00f3\u0142owych raport\u00f3w, kt\u00f3re wspieraj\u0105 podejmowanie decyzji biznesowych.</p> </li> </ul>"},{"location":"licencing/commercial-licence/#warunki","title":"Warunki:","text":"<ul> <li>Koszt licencji komercyjnej wynosi 20 tys z\u0142 netto rocznie. Jest to inwestycja, kt\u00f3ra zapewnia dost\u0119p do zaawansowanych narz\u0119dzi i wsparcia, co przek\u0142ada si\u0119 na zwi\u0119kszenie efektywno\u015bci i konkurencyjno\u015bci firmy.</li> <li>Wyj\u0105tek: Je\u015bli dostarczysz dowoln\u0105, kompletn\u0105 integracj\u0119 do oprogramowania, do kt\u00f3rego jeszcze nie mamy integracji, kwota za licencj\u0119 zmniejsza si\u0119 do 4 tys z\u0142 netto rocznie.</li> </ul>"},{"location":"licencing/commercial-licence/#co-zawiera-taka-licencja","title":"Co zawiera taka licencja:","text":"<ul> <li> <p>10h szkolenia z u\u017cywania i dobrych praktyk: W ramach licencji oferujemy kompleksowe szkolenie, kt\u00f3re obejmuje zar\u00f3wno podstawy, jak i zaawansowane techniki korzystania z naszych narz\u0119dzi. Szkolenie prowadzone jest przez ekspert\u00f3w, kt\u00f3rzy dziel\u0105 si\u0119 najlepszymi praktykami i strategiami, aby Twoja firma mog\u0142a w pe\u0142ni wykorzysta\u0107 potencja\u0142 naszych rozwi\u0105za\u0144.</p> </li> <li> <p>Wszystkie prompty, kt\u00f3re u\u017cywamy do pracy: Licencja zapewnia dost\u0119p do pe\u0142nej gamy prompt\u00f3w, kt\u00f3re s\u0105 kluczowe w codziennej pracy analitycznej. Dzi\u0119ki temu Twoja firma mo\u017ce korzysta\u0107 z tych samych narz\u0119dzi, kt\u00f3re my u\u017cywamy do osi\u0105gania najlepszych wynik\u00f3w.</p> </li> <li> <p>Aktualizacje przez trwanie licencji: W ramach licencji zapewniamy regularne aktualizacje naszych narz\u0119dzi, co gwarantuje, \u017ce zawsze b\u0119dziesz mie\u0107 dost\u0119p do najnowszych funkcji i usprawnie\u0144. Dzi\u0119ki temu Twoja firma pozostaje na czo\u0142owej pozycji w dynamicznie zmieniaj\u0105cym si\u0119 \u015brodowisku biznesowym.</p> </li> </ul>"},{"location":"licencing/educational-licence/","title":"Licencja edukacyjna","text":""},{"location":"licencing/educational-licence/#wprowadzenie","title":"Wprowadzenie","text":"<p>Licencja edukacyjna DataBackbone zosta\u0142a stworzona z my\u015bl\u0105 o wspieraniu edukacji w dziedzinie analityki danych oraz finans\u00f3w. Naszym celem jest umo\u017cliwienie studentom i instytucjom edukacyjnym dost\u0119pu do zaawansowanych narz\u0119dzi analitycznych, kt\u00f3re pomog\u0105 w nauce i rozwoju umiej\u0119tno\u015bci niezb\u0119dnych na wsp\u00f3\u0142czesnym rynku pracy.</p>"},{"location":"licencing/educational-licence/#warunki-licencji","title":"Warunki licencji","text":"<p>Aby skorzysta\u0107 z licencji edukacyjnej, wystarczy spe\u0142ni\u0107 kilka prostych warunk\u00f3w:</p> <ol> <li> <p>Zastosowanie edukacyjne: Licencja jest przeznaczona wy\u0142\u0105cznie do cel\u00f3w edukacyjnych, takich jak projekty studenckie, kursy akademickie czy badania naukowe zwi\u0105zane z analityk\u0105 danych i finansami.</p> </li> <li> <p>Zg\u0142oszenie ch\u0119ci u\u017cycia: Osoby lub instytucje zainteresowane korzystaniem z DataBackbone w celach edukacyjnych powinny wys\u0142a\u0107 wiadomo\u015b\u0107 e-mail na adres licence@databackbone.tech. W wiadomo\u015bci nale\u017cy kr\u00f3tko opisa\u0107, w jaki spos\u00f3b planowane jest wykorzystanie narz\u0119dzi DataBackbone.</p> </li> <li> <p>Akceptacja warunk\u00f3w: Po przes\u0142aniu zg\u0142oszenia i jego akceptacji, u\u017cytkownik otrzyma potwierdzenie oraz dost\u0119p do narz\u0119dzi DataBackbone na warunkach licencji edukacyjnej.</p> </li> </ol>"},{"location":"licencing/educational-licence/#korzysci-z-licencji-edukacyjnej","title":"Korzy\u015bci z licencji edukacyjnej","text":"<ul> <li> <p>Dost\u0119p do zaawansowanych narz\u0119dzi: U\u017cytkownicy licencji edukacyjnej maj\u0105 dost\u0119p do pe\u0142nej gamy narz\u0119dzi analitycznych DataBackbone, co pozwala na praktyczne zastosowanie teorii w rzeczywistych projektach.</p> </li> <li> <p>Wsparcie techniczne: Oferujemy wsparcie techniczne dla u\u017cytkownik\u00f3w licencji edukacyjnej, aby zapewni\u0107 p\u0142ynne i efektywne korzystanie z naszych narz\u0119dzi.</p> </li> <li> <p>Mo\u017cliwo\u015b\u0107 rozwoju umiej\u0119tno\u015bci: Dzi\u0119ki licencji edukacyjnej studenci i wyk\u0142adowcy mog\u0105 rozwija\u0107 swoje umiej\u0119tno\u015bci analityczne, co zwi\u0119ksza ich konkurencyjno\u015b\u0107 na rynku pracy.</p> </li> </ul>"},{"location":"licencing/noncommercial-licence/","title":"Bezp\u0142atna licencja dla Twojej firmy","text":""},{"location":"licencing/noncommercial-licence/#wprowadzenie","title":"Wprowadzenie","text":"<p>Data Backbone oferuje mo\u017cliwo\u015b\u0107 bezp\u0142atnego korzystania z naszych narz\u0119dzi dla firm, kt\u00f3re spe\u0142ni\u0105 okre\u015blone warunki. Naszym celem jest wspieranie inicjatyw, kt\u00f3re przyczyniaj\u0105 si\u0119 do dobra spo\u0142ecznego, dlatego zach\u0119camy do wsparcia schronisk dla zwierz\u0105t.</p>"},{"location":"licencing/noncommercial-licence/#warunki-uzyskania-bezpatnej-licencji-na-data-backbone","title":"Warunki uzyskania bezp\u0142atnej licencji na Data Backbone","text":"<p>Aby uzyska\u0107 bezp\u0142atn\u0105 licencj\u0119, nale\u017cy:</p> <ol> <li> <p>Dokona\u0107 darowizny: Przed rozpocz\u0119ciem korzystania z Data Backbone, prosimy o dokonanie wp\u0142aty minimum 500 z\u0142 na dowolne schronisko dla zwierz\u0105t. Wp\u0142ata ta jest wyrazem wsparcia dla organizacji, kt\u00f3re dbaj\u0105 o zwierz\u0119ta w potrzebie.</p> </li> <li> <p>Przes\u0142a\u0107 potwierdzenie: Po dokonaniu wp\u0142aty, prosimy o przes\u0142anie zdj\u0119cia potwierdzenia przelewu na adres e-mail: licence@databackbone.tech. W wiadomo\u015bci prosimy o podanie nazwy firmy oraz danych kontaktowych, co u\u0142atwi nam proces weryfikacji.</p> </li> <li> <p>Otrzyma\u0107 potwierdzenie: Po zweryfikowaniu przes\u0142anego potwierdzenia, skontaktujemy si\u0119 z Tob\u0105, aby potwierdzi\u0107 przyznanie bezp\u0142atnej licencji oraz przekaza\u0107 niezb\u0119dne informacje dotycz\u0105ce korzystania z naszych narz\u0119dzi.</p> </li> </ol>"},{"location":"licencing/noncommercial-licence/#korzysci-z-bezpatnej-licencji","title":"Korzy\u015bci z bezp\u0142atnej licencji","text":"<ul> <li> <p>Dost\u0119p do pe\u0142nej funkcjonalno\u015bci: Bezp\u0142atna licencja zapewnia dost\u0119p do wszystkich funkcji Data Backbone, co pozwala na pe\u0142ne wykorzystanie potencja\u0142u naszych narz\u0119dzi w Twojej firmie.</p> </li> <li> <p>Wspieranie spo\u0142eczno\u015bci: Korzystaj\u0105c z bezp\u0142atnej licencji, przyczyniasz si\u0119 do wsparcia schronisk dla zwierz\u0105t, co jest wa\u017cnym krokiem w budowaniu lepszego spo\u0142ecze\u0144stwa.</p> </li> </ul>"},{"location":"prompts/analysis/","title":"Prompty u\u017cywane podczas analizy struktur danych","text":""},{"location":"prompts/analysis/#1-generowanie-wskaznikow-na-podstawie-struktur-danych","title":"1. Generowanie wska\u017anik\u00f3w na podstawie struktur danych","text":"<pre><code>B\u0119dziesz analizowa\u0107 surowe struktury danych dla klienta.\nNapiszesz list\u0119 potencjalnych wsp\u00f3\u0142czynnik\u00f3w, metryk, kt\u00f3re z punktu widzenia biznesu b\u0119d\u0105 potrzebne.\n\nStruktura nr 1 - SampleCustomerTasks:\n{\n        \"id\": \"86byf6a2v\",\n        \"url\": \"https://app.clickup.com/t/86byf6a2v\",\n        \"list\": {\n            \"id\": \"901503260052\",\n            \"name\": \"Taski\",\n            \"access\": true\n        },\n        \"name\": \"analiza SSOT: potencjalna struktura danych\",\n        \"tags\": [],\n        \"space\": {\n            \"id\": \"90151384174\"\n        },\n        \"folder\": {\n            \"id\": \"90152051126\",\n            \"name\": \"Plona Consulting \",\n            \"hidden\": false,\n            \"access\": true\n        },\n        \"parent\": null,\n        \"points\": null,\n        \"status\": {\n            \"status\": \"zako\u0144czone\",\n            \"id\": \"c90152051126_SM0xvYxN\",\n            \"color\": \"#008844\",\n            \"type\": \"done\",\n            \"orderindex\": 5\n        },\n        \"creator\": {\n            \"id\": 62683896,\n            \"username\": \"Usprawniacze Firm\",\n            \"color\": \"\",\n            \"email\": \"kontakt@usprawniaczefirm.pl\",\n            \"profilePicture\": null\n        },\n        \"project\": {\n            \"id\": \"90152051126\",\n            \"name\": \"Plona Consulting \",\n            \"hidden\": false,\n            \"access\": true\n        },\n        \"sharing\": {\n            \"public\": false,\n            \"public_share_expires_on\": null,\n            \"public_fields\": [\n                \"assignees\",\n                \"priority\",\n                \"due_date\",\n                \"content\",\n                \"comments\",\n                \"attachments\",\n                \"customFields\",\n                \"subtasks\",\n                \"tags\",\n                \"checklists\",\n                \"coverimage\"\n            ],\n            \"token\": null,\n            \"seo_optimized\": false\n        },\n        \"team_id\": \"9015418181\",\n        \"archived\": false,\n        \"due_date\": null,\n        \"priority\": null,\n        \"watchers\": [\n            {\n                \"id\": 62683896,\n                \"username\": \"Usprawniacze Firm\",\n                \"color\": \"\",\n                \"initials\": \"UF\",\n                \"email\": \"kontakt@usprawniaczefirm.pl\",\n                \"profilePicture\": null\n            },\n            {\n                \"id\": 38457152,\n                \"username\": \"apifex@gmail.com\",\n                \"color\": \"#ff5251\",\n                \"initials\": \"A\",\n                \"email\": \"apifex@gmail.com\",\n                \"profilePicture\": null\n            }\n        ],\n        \"assignees\": [\n            {\n                \"id\": 38457152,\n                \"username\": \"apifex@gmail.com\",\n                \"color\": \"#ff5251\",\n                \"initials\": \"A\",\n                \"email\": \"apifex@gmail.com\",\n                \"profilePicture\": null\n            }\n        ],\n        \"custom_id\": null,\n        \"date_done\": null,\n        \"locations\": [],\n        \"checklists\": [],\n        \"orderindex\": \"119424322.00033590000000000000000000000000\",\n        \"start_date\": null,\n        \"time_spent\": 10800000,\n        \"date_closed\": null,\n        \"description\": \"\",\n        \"__IMTINDEX__\": 1,\n        \"date_created\": \"2024-04-22T19:18:51.118Z\",\n        \"date_updated\": \"2024-04-30T07:56:47.659Z\",\n        \"dependencies\": [],\n        \"linked_tasks\": [],\n        \"text_content\": \"\",\n        \"__IMTLENGTH__\": 42,\n        \"custom_fields\": {\n            \"Pracownik\": [\n                {\n                    \"id\": 38457152,\n                    \"username\": \"apifex@gmail.com\",\n                    \"email\": \"apifex@gmail.com\",\n                    \"color\": \"#ff5251\",\n                    \"initials\": \"A\",\n                    \"profilePicture\": null\n                }\n            ]\n        },\n        \"time_estimate\": 0,\n        \"custom_item_id\": 0,\n        \"group_assignees\": [],\n        \"permission_level\": \"create\",\n        \"custom_fields_original\": [\n            {\n                \"id\": \"470c2681-e6ec-4e52-845c-4cfac15e32a2\",\n                \"name\": \"Komentarz\",\n                \"type\": \"text\",\n                \"type_config\": {\n                    \"ai\": {\n                        \"format\": \"bullet\",\n                        \"source\": \"summary\"\n                    }\n                },\n                \"date_created\": \"2024-04-05T16:57:12.168Z\",\n                \"hide_from_guests\": false,\n                \"required\": false\n            },\n            {\n                \"id\": \"55e6a7a8-4465-4f12-b4f7-1f2a76ecdbe8\",\n                \"name\": \"Estymata\",\n                \"type\": \"drop_down\",\n                \"type_config\": {\n                    \"new_drop_down\": true,\n                    \"options\": [\n                        {\n                            \"id\": \"a82a9299-2ad5-4e1f-9058-2f44fb961e71\",\n                            \"name\": \"1-2h\",\n                            \"color\": null,\n                            \"orderindex\": 0\n                        },\n                        {\n                            \"id\": \"ecef5947-0613-4753-b6ca-f2567b11d053\",\n                            \"name\": \"3-6h\",\n                            \"color\": null,\n                            \"orderindex\": 1\n                        },\n                        {\n                            \"id\": \"93f9d5ed-3068-4284-acf4-cf0f5a6fa4ec\",\n                            \"name\": \"7-11h\",\n                            \"color\": null,\n                            \"orderindex\": 2\n                        },\n                        {\n                            \"id\": \"7ed96cae-4602-4c78-8125-17e88a21422f\",\n                            \"name\": \"proces ci\u0105g\u0142y\",\n                            \"color\": null,\n                            \"orderindex\": 3\n                        },\n                        {\n                            \"id\": \"f9fe1d7f-bed4-4322-a9f9-deb8a0bdacb6\",\n                            \"name\": \"11-15h\",\n                            \"color\": null,\n                            \"orderindex\": 4\n                        },\n                        {\n                            \"id\": \"6f2f2b22-878c-4a02-ab2b-38f6a5b81388\",\n                            \"name\": \"16-20h\",\n                            \"color\": null,\n                            \"orderindex\": 5\n                        },\n                        {\n                            \"id\": \"2a10def4-a43d-4718-9fed-9280d3777896\",\n                            \"name\": \"21-25h\",\n                            \"color\": null,\n                            \"orderindex\": 6\n                        },\n                        {\n                            \"id\": \"5652683a-03ad-44ef-b567-b9e9ab0428b0\",\n                            \"name\": \"26-30h\",\n                            \"color\": null,\n                            \"orderindex\": 7\n                        },\n                        {\n                            \"id\": \"14670781-5f06-4888-a1a4-ea7bbc64de1a\",\n                            \"name\": \"31-35h\",\n                            \"color\": null,\n                            \"orderindex\": 8\n                        },\n                        {\n                            \"id\": \"ded7e9a1-9b89-4843-961c-17955038b19e\",\n                            \"name\": \"36-40h\",\n                            \"color\": null,\n                            \"orderindex\": 9\n                        },\n                        {\n                            \"id\": \"8808f869-94c8-4141-b992-c183ce4ddf4f\",\n                            \"name\": \"41-45h\",\n                            \"color\": null,\n                            \"orderindex\": 10\n                        },\n                        {\n                            \"id\": \"439555f1-fe4a-402d-8548-62bf799b2387\",\n                            \"name\": \"46-50h\",\n                            \"color\": null,\n                            \"orderindex\": 11\n                        }\n                    ]\n                },\n                \"date_created\": \"2024-04-15T10:13:43.516Z\",\n                \"hide_from_guests\": false,\n                \"required\": true\n            },\n            {\n                \"id\": \"d336b204-d49e-40e5-8085-70fc48927784\",\n                \"name\": \"Pracownik\",\n                \"type\": \"users\",\n                \"type_config\": {\n                    \"single_user\": false,\n                    \"include_groups\": true,\n                    \"include_guests\": true,\n                    \"include_team_members\": true\n                },\n                \"date_created\": \"2024-04-05T16:45:35.124Z\",\n                \"hide_from_guests\": false,\n                \"value\": [\n                    {\n                        \"id\": 38457152,\n                        \"username\": \"apifex@gmail.com\",\n                        \"email\": \"apifex@gmail.com\",\n                        \"color\": \"#ff5251\",\n                        \"initials\": \"A\",\n                        \"profilePicture\": null\n                    }\n                ],\n                \"required\": true\n            },\n            {\n                \"id\": \"16bc1312-dc7e-4d96-a39e-0d1391018c1c\",\n                \"name\": \"Typ zadania\",\n                \"type\": \"drop_down\",\n                \"type_config\": {\n                    \"new_drop_down\": true,\n                    \"options\": [\n                        {\n                            \"id\": \"c9d0004e-dc97-447c-a43e-81a51d1e4c47\",\n                            \"name\": \"konsultacje\",\n                            \"color\": \"#2ecd6f\",\n                            \"orderindex\": 0\n                        },\n                        {\n                            \"id\": \"8977b7b1-aa71-424b-927d-6b090b3723b1\",\n                            \"name\": \"wdro\u017cenie\",\n                            \"color\": \"#0231E8\",\n                            \"orderindex\": 1\n                        },\n                        {\n                            \"id\": \"af21c60d-4815-4f01-a18a-429b44e2fdfd\",\n                            \"name\": \"tworzenie instrukcji / raport\u00f3w\",\n                            \"color\": \"#f9d900\",\n                            \"orderindex\": 2\n                        },\n                        {\n                            \"id\": \"2696cb10-55e2-4973-b6b0-6f4410a369f8\",\n                            \"name\": \"gaszenie po\u017car\u00f3w\",\n                            \"color\": \"#800000\",\n                            \"orderindex\": 3\n                        },\n                        {\n                            \"id\": \"f302e17a-accc-4efb-809a-7c10a35f1e15\",\n                            \"name\": \"przegl\u0105d\",\n                            \"color\": \"#81B1FF\",\n                            \"orderindex\": 4\n                        },\n                        {\n                            \"id\": \"1bc4e021-4853-4360-af79-00a625421203\",\n                            \"name\": \"research\",\n                            \"color\": \"#EA80FC\",\n                            \"orderindex\": 5\n                        },\n                        {\n                            \"id\": \"a3c6dfcb-782d-47b0-9806-b7fd126eb12e\",\n                            \"name\": \"czynno\u015bci operacyjne\",\n                            \"color\": \"#FF7FAB\",\n                            \"orderindex\": 6\n                        },\n                        {\n                            \"id\": \"c02976f4-6fc8-4ba6-8189-8005f2b02255\",\n                            \"name\": \"programowanie/no-code/low-code\",\n                            \"color\": \"#E65100\",\n                            \"orderindex\": 7\n                        },\n                        {\n                            \"id\": \"f6314b2d-61c2-4a05-89c2-1fa596b25c09\",\n                            \"name\": \"Inne\",\n                            \"color\": null,\n                            \"orderindex\": 8\n                        }\n                    ]\n                },\n                \"date_created\": \"2024-03-18T11:50:51.252Z\",\n                \"hide_from_guests\": false,\n                \"required\": true\n            }\n        ]\n    }\n\n\nStruktura nr 2 - SampleInvoice:\n\n{\n        \"id\": \"in_1PRfvIBYfFbLWOb7nHeZVhoC\",\n        \"tax\": null,\n        \"paid\": true,\n        \"lines\": {\n            \"object\": \"list\",\n            \"data\": [\n                {\n                    \"id\": \"il_1PRfvIBYfFbLWOb704DdYVqK\",\n                    \"object\": \"line_item\",\n                    \"amount\": 61377,\n                    \"amount_excluding_tax\": 61377,\n                    \"currency\": \"pln\",\n                    \"description\": \"1 \u00d7 Support techniczny Implemo dla e-commerce (at 613.77 z\u0142 / month)\",\n                    \"discount_amounts\": [],\n                    \"discountable\": true,\n                    \"discounts\": [],\n                    \"invoice\": \"in_1PRfvIBYfFbLWOb7nHeZVhoC\",\n                    \"livemode\": true,\n                    \"metadata\": {},\n                    \"period\": {\n                        \"end\": 1720985726,\n                        \"start\": 1718393726\n                    },\n                    \"plan\": {\n                        \"id\": \"price_1Oc8cbBYfFbLWOb75NKXonGe\",\n                        \"object\": \"plan\",\n                        \"active\": true,\n                        \"aggregate_usage\": null,\n                        \"amount\": 61377,\n                        \"amount_decimal\": \"61377\",\n                        \"billing_scheme\": \"per_unit\",\n                        \"created\": 1706111053,\n                        \"currency\": \"pln\",\n                        \"interval\": \"month\",\n                        \"interval_count\": 1,\n                        \"livemode\": true,\n                        \"metadata\": {\n                            \"cancel_early\": \"true\",\n                            \"custom_id\": \"BRAZ\",\n                            \"delivery_enabled\": \"false\",\n                            \"has_quantity\": \"false\",\n                            \"hidden\": \"false\",\n                            \"name\": \"Br\u0105zowy (2h/msc)\",\n                            \"net_price\": \"499\",\n                            \"order\": \"1\",\n                            \"shipping\": \"false\",\n                            \"shipping_phone\": \"false\",\n                            \"show_active_until_counter\": \"false\",\n                            \"show_net_price\": \"false\",\n                            \"uuid\": \"90c1b394-6f5b-430e-a3d9-516480dfb486\",\n                            \"vat_rate\": \"23\"\n                        },\n                        \"meter\": null,\n                        \"nickname\": null,\n                        \"product\": \"prod_PR0duHXCSoUNO8\",\n                        \"tiers_mode\": null,\n                        \"transform_usage\": null,\n                        \"trial_period_days\": null,\n                        \"usage_type\": \"licensed\"\n                    },\n                    \"price\": {\n                        \"id\": \"price_1Oc8cbBYfFbLWOb75NKXonGe\",\n                        \"object\": \"price\",\n                        \"active\": true,\n                        \"billing_scheme\": \"per_unit\",\n                        \"created\": 1706111053,\n                        \"currency\": \"pln\",\n                        \"custom_unit_amount\": null,\n                        \"livemode\": true,\n                        \"lookup_key\": null,\n                        \"metadata\": {\n                            \"cancel_early\": \"true\",\n                            \"custom_id\": \"BRAZ\",\n                            \"delivery_enabled\": \"false\",\n                            \"has_quantity\": \"false\",\n                            \"hidden\": \"false\",\n                            \"name\": \"Br\u0105zowy (2h/msc)\",\n                            \"net_price\": \"499\",\n                            \"order\": \"1\",\n                            \"shipping\": \"false\",\n                            \"shipping_phone\": \"false\",\n                            \"show_active_until_counter\": \"false\",\n                            \"show_net_price\": \"false\",\n                            \"uuid\": \"90c1b394-6f5b-430e-a3d9-516480dfb486\",\n                            \"vat_rate\": \"23\"\n                        },\n                        \"nickname\": null,\n                        \"product\": \"prod_PR0duHXCSoUNO8\",\n                        \"recurring\": {\n                            \"aggregate_usage\": null,\n                            \"interval\": \"month\",\n                            \"interval_count\": 1,\n                            \"meter\": null,\n                            \"trial_period_days\": null,\n                            \"usage_type\": \"licensed\"\n                        },\n                        \"tax_behavior\": \"unspecified\",\n                        \"tiers_mode\": null,\n                        \"transform_quantity\": null,\n                        \"type\": \"recurring\",\n                        \"unit_amount\": 61377,\n                        \"unit_amount_decimal\": \"61377\"\n                    },\n                    \"proration\": false,\n                    \"proration_details\": {\n                        \"credited_items\": null\n                    },\n                    \"quantity\": 1,\n                    \"subscription\": \"sub_1OuK3mBYfFbLWOb7ojXCmseb\",\n                    \"subscription_item\": \"si_PjnfFUvyNctOC0\",\n                    \"tax_amounts\": [],\n                    \"tax_rates\": [],\n                    \"type\": \"subscription\",\n                    \"unit_amount_excluding_tax\": \"61377\"\n                }\n            ],\n            \"has_more\": false,\n            \"total_count\": 1,\n            \"url\": \"/v1/invoices/in_1PRfvIBYfFbLWOb7nHeZVhoC/lines\"\n        },\n        \"quote\": null,\n        \"total\": 61377,\n        \"charge\": \"ch_3PRgrYBYfFbLWOb71xGnI9aB\",\n        \"footer\": null,\n        \"issuer\": {\n            \"type\": \"self\"\n        },\n        \"number\": \"87B79AA0-0080\",\n        \"object\": null,\n        \"status\": \"paid\",\n        \"created\": \"2024-06-14T19:36:33.000Z\",\n        \"currency\": \"pln\",\n        \"customer\": \"cus_PjnfDikdUdoua2\",\n        \"discount\": null,\n        \"due_date\": null,\n        \"livemode\": true,\n        \"metadata\": {},\n        \"subtotal\": 61377,\n        \"attempted\": true,\n        \"discounts\": [],\n        \"rendering\": null,\n        \"amount_due\": 61377,\n        \"period_end\": \"2024-06-14T19:35:26.000Z\",\n        \"test_clock\": null,\n        \"amount_paid\": 61377,\n        \"application\": \"ca_JTzTQ7BiOPPZf5fzP01hRWaI1oEClAxB\",\n        \"description\": null,\n        \"invoice_pdf\": \"https://pay.stripe.com/invoice/acct_1NXv1zBYfFbLWOb7/live_YWNjdF8xTlh2MXpCWWZGYkxXT2I3LF9RSUdTWDJzN0NQRFJTN2RucTNPRnlON09qZmw5QkFZLDEwOTE3NjAzMg02004vG70dVQ/pdf?s=ap\",\n        \"tax_percent\": null,\n        \"__IMTINDEX__\": 1,\n        \"account_name\": \"Implemo sp\u00f3\u0142ka z ograniczon\u0105 odpowiedzialno\u015bci\u0105\",\n        \"auto_advance\": false,\n        \"effective_at\": 1718397404,\n        \"from_invoice\": null,\n        \"on_behalf_of\": null,\n        \"period_start\": \"2024-05-14T19:35:26.000Z\",\n        \"subscription\": \"sub_1OuK3mBYfFbLWOb7ojXCmseb\",\n        \"__IMTLENGTH__\": 81,\n        \"attempt_count\": 1,\n        \"automatic_tax\": {\n            \"enabled\": false,\n            \"liability\": null,\n            \"status\": null\n        },\n        \"custom_fields\": null,\n        \"customer_name\": \"BARTOSZ MICHA\u0141 KA\u0141U\u017bNY\",\n        \"shipping_cost\": null,\n        \"transfer_data\": null,\n        \"billing_reason\": \"subscription_cycle\",\n        \"customer_email\": \"bartosz.kaluzny@wp.pl\",\n        \"customer_phone\": null,\n        \"default_source\": null,\n        \"ending_balance\": 0,\n        \"payment_intent\": \"pi_3PRgrYBYfFbLWOb71VyNoc1B\",\n        \"receipt_number\": null,\n        \"account_country\": \"PL\",\n        \"account_tax_ids\": null,\n        \"amount_shipping\": 0,\n        \"latest_revision\": null,\n        \"amount_remaining\": 0,\n        \"customer_address\": {\n            \"city\": \"\",\n            \"country\": \"PL\",\n            \"line1\": \"\",\n            \"line2\": \"\",\n            \"postal_code\": \"08110\",\n            \"state\": \"\"\n        },\n        \"customer_tax_ids\": [],\n        \"paid_out_of_band\": false,\n        \"payment_settings\": {\n            \"default_mandate\": null,\n            \"payment_method_options\": null,\n            \"payment_method_types\": null\n        },\n        \"shipping_details\": null,\n        \"starting_balance\": 0,\n        \"collection_method\": \"charge_automatically\",\n        \"customer_shipping\": null,\n        \"default_tax_rates\": [],\n        \"rendering_options\": null,\n        \"total_tax_amounts\": [],\n        \"hosted_invoice_url\": \"https://invoice.stripe.com/i/acct_1NXv1zBYfFbLWOb7/live_YWNjdF8xTlh2MXpCWWZGYkxXT2I3LF9RSUdTWDJzN0NQRFJTN2RucTNPRnlON09qZmw5QkFZLDEwOTE3NjAzMg02004vG70dVQ?s=ap\",\n        \"status_transitions\": {\n            \"finalized_at\": \"2024-06-14T20:36:44.000Z\",\n            \"paid_at\": \"2024-06-14T20:36:44.000Z\"\n        },\n        \"customer_tax_exempt\": \"none\",\n        \"total_excluding_tax\": 61377,\n        \"next_payment_attempt\": null,\n        \"statement_descriptor\": null,\n        \"subscription_details\": {\n            \"metadata\": {}\n        },\n        \"webhooks_delivered_at\": \"2024-06-14T19:36:34.000Z\",\n        \"application_fee_amount\": null,\n        \"default_payment_method\": null,\n        \"subtotal_excluding_tax\": 61377,\n        \"total_discount_amounts\": [],\n        \"last_finalization_error\": null,\n        \"pre_payment_credit_notes_amount\": 0,\n        \"post_payment_credit_notes_amount\": 0\n    }\n\n\n\nOdpowiedz tylko list\u0105 potencjalnych wsp\u00f3\u0142czynnik\u00f3w, metryk, kt\u00f3re mo\u017cemy mierzy\u0107/liczy\u0107 na podstawie podanych struktur.\n\nOdpowiedz zar\u00f3wno list\u0105 wsp\u00f3\u0142czynnik\u00f3w, metryk, kt\u00f3re wyst\u0119puj\u0105 w obr\u0119bie ka\u017cdej ze struktur oraz tymi, kt\u00f3re mo\u017cemy uzyska\u0107 \u0142\u0105cz\u0105c te dane.\n</code></pre>"},{"location":"prompts/code/","title":"Prompty u\u017cywane podczas warszat\u00f3w","text":""},{"location":"prompts/code/#1-generowanie-wytycznych-pod-integracje-z-api","title":"1. Generowanie wytycznych pod integracje z API","text":"<p>Do dzia\u0142ania prompta wymagane jest Assistant API / Vector Store oraz dokumentacja do API w zjadliwej dla AI formie.</p> <pre><code>### System prompt\n\nJako ekspert w integracji API, Twoim zadaniem jest przygotowanie szczeg\u00f3\u0142owych wymaga\u0144 i przyk\u0142adowego kodu do integracji pojedynczego zasobu API wskazanego przez u\u017cytkownika. Bazuj\u0105c na dostarczonej dokumentacji API, wykonaj nast\u0119puj\u0105ce kroki:\n\n1. Zbierz i przedstaw kluczowe informacje o endpoincie:\n   - Dok\u0142adny URL\n   - Metoda HTTP\n   - Wymagania autoryzacji\n   - Wymagane i opcjonalne parametry wej\u015bciowe\n   - Format danych wej\u015bciowych\n   - Format odpowiedzi\n\n2. Opisz niezb\u0119dne kroki do przygotowania \u015brodowiska:\n   - Wymagane biblioteki (np. requests)\n   - Konfiguracja zmiennych \u015brodowiskowych\n\n3. Zaproponuj implementacj\u0119 funkcji do autoryzacji:\n   - Metoda generowania nag\u0142\u00f3wk\u00f3w autoryzacji\n   - Obs\u0142uga r\u00f3\u017cnych typ\u00f3w autoryzacji\n\n4. Przedstaw szkic funkcji do pobrania zasobu:\n   - Definicja funkcji z odpowiednimi parametrami\n   - Konstrukcja URL i payload'u\n   - Wykonanie zapytania HTTP\n   - Podstawowa obs\u0142uga b\u0142\u0119d\u00f3w\n   - Zwracanie danych odpowiedzi\n\n5. Opisz strategi\u0119 obs\u0142ugi b\u0142\u0119d\u00f3w i wyj\u0105tk\u00f3w:\n   - Typowe b\u0142\u0119dy biblioteki requests\n   - B\u0142\u0119dy specyficzne dla danego API\n   - Propozycje czytelnych komunikat\u00f3w b\u0142\u0119du\n\n6. Opisz dok\u0142adnie pe\u0142n\u0105 struktur\u0119 odpowiedzi w formacie domy\u015blnym dla API wraz z opisami kluczy\n\n7. Przygotuj przyk\u0142adowy kod w Python, kt\u00f3ry zaimplementuje powy\u017csze punkty dla wskazanego zasobu API.\n\nPami\u0119taj o dostosowaniu odpowiedzi do specyfiki konkretnego API i zasobu wskazanego przez u\u017cytkownika. Twoja odpowied\u017a powinna by\u0107 szczeg\u00f3\u0142owa, praktyczna i gotowa do implementacji.\n\n\n### User Prompt\n\nStw\u00f3rz pe\u0142en opis zasobu Klienci w Saldeo\n</code></pre>"},{"location":"prompts/intro/","title":"Wprowadzenie do Dokumentacji Prompt\u00f3w","text":"<p>Ca\u0142o\u015b\u0107 tej dokumentacji jest dla Ciebie wsadem do AI</p> <p>Witaj w dokumentacji prompt\u00f3w, kt\u00f3ra zosta\u0142a stworzona, aby wspiera\u0107 Ci\u0119 w efektywnym wykorzystaniu sztucznej inteligencji w Twoich projektach. Ta dokumentacja jest wszechstronnym \u017ar\u00f3d\u0142em wiedzy, kt\u00f3re pomo\u017ce Ci w r\u00f3\u017cnych aspektach pracy z AI, od warsztat\u00f3w z klientem po generowanie zaawansowanych rozwi\u0105za\u0144.</p>"},{"location":"prompts/intro/#zawartosc-dokumentacji","title":"Zawarto\u015b\u0107 Dokumentacji","text":""},{"location":"prompts/intro/#warsztaty-z-klientem","title":"Warsztaty z Klientem","text":"<p>Sekcja ta zawiera wskaz\u00f3wki i przyk\u0142ady, jak prowadzi\u0107 efektywne warsztaty z klientami, wykorzystuj\u0105c AI do zrozumienia ich potrzeb i dostarczania warto\u015bciowych rozwi\u0105za\u0144.</p>"},{"location":"prompts/intro/#generowanie-i-analiza-kodu","title":"Generowanie i Analiza Kodu","text":"<p>Dowiedz si\u0119, jak u\u017cywa\u0107 AI do automatyzacji procesu generowania kodu oraz jak analizowa\u0107 istniej\u0105cy kod w celu optymalizacji i poprawy jego jako\u015bci.</p>"},{"location":"prompts/intro/#generowanie-rozwiazan","title":"Generowanie Rozwi\u0105za\u0144","text":"<p>Odkryj, jak AI mo\u017ce wspiera\u0107 Ci\u0119 w tworzeniu innowacyjnych rozwi\u0105za\u0144, kt\u00f3re odpowiadaj\u0105 na konkretne wyzwania biznesowe i technologiczne.</p>"},{"location":"prompts/intro/#generowanie-graphow","title":"Generowanie Graph\u00f3w","text":"<p>Poznaj metody generowania graph\u00f3w i wizualizacji danych przy u\u017cyciu AI, co pozwala na lepsze zrozumienie i prezentacj\u0119 z\u0142o\u017conych informacji.</p>"},{"location":"prompts/workshops/","title":"Prompty u\u017cywane podczas warszat\u00f3w","text":""},{"location":"prompts/workshops/#1-generowanie-planu-dziaan-na-podstawie-informacji-od-klienta","title":"1. Generowanie planu dzia\u0142a\u0144 na podstawie informacji od klienta","text":"<pre><code>Jako analityk danych, stw\u00f3rz szczeg\u00f3\u0142ow\u0105 roadmap\u0119 dzia\u0142a\u0144 przetwarzania danych.\n\nRoadmapa zaczyna si\u0119 od zasob\u00f3w surowych - dane wej\u015bciowe\n\u0141\u0105czenie i przetwarzanie zasob\u00f3w surowych tworzy encje po\u015brednie.\n\u0141\u0105czenie i przetwarzanie encji po\u015brednich tworzy wska\u017aniki - oczekiwane rezultaty\n\nSekcje roadmapy zawsze s\u0105 3:\n- ekstrakcja danych z zasob\u00f3w surowych\n- przetwarzanie danych encji po\u015brednich\n- \u0142\u0105czenie encji po\u015brednich we wska\u017aniki\n\nKa\u017cdy zas\u00f3b, encja po\u015brednia oraz wska\u017anik maj\u0105 by\u0107 oddzielnym etapem roadmapy w obr\u0119bie sekcji.\n\nDla ka\u017cdego zasobu, encji po\u015bredniej i wska\u017anika wygeneruj po 2 punkty - cz\u0119\u015b\u0107 biznesow\u0105 i cz\u0119\u015b\u0107 techniczn\u0105:\nCz\u0119\u015b\u0107 biznesowa (dla decydenta):\n- Opracuj dok\u0142adn\u0105 i zrozumia\u0142\u0105 dla osoby technicznej definicj\u0119\n- Wyja\u015bnij jej rol\u0119 w procesie\n- Opisz, jak wp\u0142ywa encja na ko\u0144cowy rezultat\n- Zaproponuj jak\u0105 wiedz\u0119 biznesow\u0105 mog\u0119 wyci\u0105gn\u0105\u0107 z encji\n- Zaproponuj proces weryfikacji wynik\u00f3w po\u015brednich\n\nCz\u0119\u015b\u0107 techniczna (dla osoby technicznej):\n- Opisz wymagane dane, kt\u00f3re musi zawiera\u0107 encja\n- Okre\u015bl \u017ar\u00f3d\u0142a danych wraz z nazw\u0105 i numerem pozycji (z zasob\u00f3w, z encji po\u015brednich)\n- Opisz w punktach proces transformacji danych do oczekiwanego rezultatu\n- Zaproponuj potencjalne punkty kontroli jako\u015bci danych \n\nPrzedstaw plan w formie sekwencyjnej, pokazuj\u0105c przep\u0142yw danych od zasob\u00f3w przez encje po\u015brednie a\u017c do wska\u017anika.\n\nTw\u00f3j plan powinien by\u0107 szczeg\u00f3\u0142owy, logiczny i pokazywa\u0107 jasn\u0105 \u015bcie\u017ck\u0119 od danych wej\u015bciowych do oczekiwanych rezultat\u00f3w, z uwzgl\u0119dnieniem wszystkich istotnych krok\u00f3w po\u015brednich i transformacji danych\n\nInformacje od klienta:\n\nZasoby klienta (dane wej\u015bciowe):\n- p\u0142atno\u015bci w Stripe\n- subskrybcje w Stripe\n- klienci w Stripe\n- p\u0142atno\u015bci  w PayU\n- klienci w PayU\n- p\u0142atno\u015bci w transakcjach bankowych\n- klienci w transakcjach bankowych\n- faktury z saldeo\n- klienci z saldeo\n\nWska\u017aniki, kt\u00f3re chce klient (oczekiwane rezultaty):\n- total sprzeda\u017c produkt\u00f3w subskrybcji  \n- lista sprzeda\u017cy produkt\u00f3w subskrybcji  \n- total sprzeda\u017c produkt\u00f3w jednorazowych \n- lista sprzeda\u017cy produkt\u00f3w jednorazowych\n</code></pre>"},{"location":"prompts/workshops/#2-generowanie-grafu-mermaid-na-podstawie-planu-dziaan-z-1","title":"2. Generowanie grafu Mermaid na podstawie planu dzia\u0142a\u0144 z 1.","text":"<pre><code>na podstawie opisu roadmapy przetwarzania danych stw\u00f3rz kod flowchart w mermaid.\n\nkonfiguracja flowcharta:\n\n- defaultRenderer: elk\n- strza\u0142ki:\n-- \u0142ami\u0105ce si\u0119 w 90 stopniach\n-- kolor bia\u0142y\n-- relacje miedzy zasobami, encjami po\u015brednimi i wska\u017anikami maj\u0105 by\u0107 zobrazowane w formie strza\u0142ek\n-- strza\u0142ki bez labeli\n\n- bloki:\n-- nazwy funkcji prezentuj bez wywo\u0142ania ()\n-- t\u0142a sekcji i t\u0142o ca\u0142ego maj\u0105 by\u0107 ciemnoszare,\n-- ka\u017cdy blok ma mie\u0107 czarny font\n-- bloki resourceFN/processFN/indicatorFN to bloki trapezowe\n-- bloki resourceDB/entityDB/indicatorDB to bloki database\n-- ka\u017cdy blok ma mie\u0107 pogrubion\u0105 odzwierciedlaj\u0105c\u0105 nazw\u0119 kroku z roadmapy i opis roli w tagach &lt;small&gt;\n\nu\u017cyj tych styli:\nclassDef getFN fill:#333,color:#fff,stroke:#f00,stroke-width:1px\nclassDef resourceDB fill:#333,color:#fff,stroke:#f00,stroke-width:1px\nclassDef processFN fill:#333,color:#fff,stroke:#ff0,stroke-width:1px\nclassDef entityDB fill:#333,color:#fff,stroke:#ff0,stroke-width:1px\nclassDef retrieveFN fill:#333,color:#fff,stroke:#0f0,stroke-width:1px\nclassDef indicatorDB fill:#333,color:#fff,stroke:#0f0,stroke-width:1px\n\n\nflowchart ma mie\u0107 6 sekcji:\n- pobieranie zasob\u00f3w - classDef getFN\n- zasoby - classDef resourceDB\n- przetwarzanie w encje pochodne - classDef processFN\n- encje pochodne - classDef entityDB\n- przetwarzanie wska\u017anik\u00f3w - classDef retrieveFN\n- wska\u017aniki - classDef indicatorDB\n\nNie tw\u00f3rz opis\u00f3w charta, potrzebuj\u0119 tylko kodu bez dodatkowych komentarzy.\n</code></pre>"},{"location":"user-guide/api-usage/","title":"U\u017cycie DataBackbone API","text":""},{"location":"user-guide/api-usage/#wprowadzenie","title":"Wprowadzenie","text":"<p>Data Backbone udost\u0119pnia API, kt\u00f3re pozwala na pobieranie danych wska\u017anik\u00f3w oraz zasob\u00f3w z zewn\u0119trznych aplikacji. Ten fragment dokumentacji opisuje, jak korzysta\u0107 z API Data Backbone, na przyk\u0142adzie integracji z platformami automatyzacji, takimi jak Make.com.</p>"},{"location":"user-guide/api-usage/#zasoby","title":"Zasoby","text":""},{"location":"user-guide/api-usage/#endpoint-api","title":"Endpoint API","text":"<p>Endpoint API Data Backbone do pobierania danych zasobu: <code>GET /data/resource/{resourceName}</code></p> <p>gdzie <code>{resourceName}</code> to nazwa zasobu, kt\u00f3rego dane chcesz pobra\u0107.</p>"},{"location":"user-guide/api-usage/#przykad-uzycia","title":"Przyk\u0142ad u\u017cycia","text":"<p>Za\u0142\u00f3\u017cmy, \u017ce chcesz pobra\u0107 dane zasobu faktur Stripe z Make.com. Oto jak mo\u017cesz to zrobi\u0107:</p> <ol> <li>W Make.com, dodaj nowy modu\u0142 HTTP.</li> <li> <p>Skonfiguruj modu\u0142 HTTP w nast\u0119puj\u0105cy spos\u00f3b:</p> </li> <li> <p>Metoda: GET</p> </li> <li>URL: <code>https://localhost:8000/data/resource/StripeInvoices</code></li> <li> <p>Nag\u0142\u00f3wki: Dodaj odpowiednie nag\u0142\u00f3wki autoryzacji, je\u015bli s\u0105 wymagane.</p> </li> <li> <p>Po wykonaniu scenariusza, Make.com pobierze dane faktur Stripe z Data Backbone w formacie JSON.</p> </li> </ol>"},{"location":"user-guide/api-usage/#format-odpowiedzi","title":"Format odpowiedzi","text":"<p>Odpowied\u017a API b\u0119dzie w formacie JSON. Przyk\u0142adowa struktura danych faktur Stripe mo\u017ce wygl\u0105da\u0107 nast\u0119puj\u0105co:</p> <pre><code>{\n  \"data\": [\n    {\n      \"id\": \"in_1234567890\",\n      \"customer\": \"cus_9876543210\",\n      \"amount\": 10000,\n      \"currency\": \"PLN\",\n      \"status\": \"paid\",\n      \"created\": \"2023-06-01T10:00:00Z\"\n    },\n    {\n      \"id\": \"in_0987654321\",\n      \"customer\": \"cus_1234567890\",\n      \"amount\": 15000,\n      \"currency\": \"PLN\",\n      \"status\": \"open\",\n      \"created\": \"2023-06-15T14:30:00Z\"\n    }\n  ],\n  \"meta\": {\n    \"lastUpdated\": \"2023-06-15T15:00:00Z\"\n  }\n}\n</code></pre>"},{"location":"user-guide/api-usage/#wskazniki","title":"Wska\u017aniki","text":""},{"location":"user-guide/api-usage/#endpoint-api_1","title":"Endpoint API","text":"<p>Endpoint API Data Backbone do pobierania danych wska\u017anika: <code>GET /data/indicator/{indicatorName}</code></p> <p>gdzie <code>{indicatorName}</code> to nazwa wska\u017anika, kt\u00f3rego dane chcesz pobra\u0107.</p>"},{"location":"user-guide/api-usage/#przykad-uzycia_1","title":"Przyk\u0142ad u\u017cycia","text":"<p>Za\u0142\u00f3\u017cmy, \u017ce chcesz pobra\u0107 dane wska\u017anika RZIS (Rachunek Zysk\u00f3w i Strat) do Make.com. Oto jak mo\u017cesz to zrobi\u0107:</p> <ol> <li>W Make.com, dodaj nowy modu\u0142 HTTP.</li> <li> <p>Skonfiguruj modu\u0142 HTTP w nast\u0119puj\u0105cy spos\u00f3b:</p> </li> <li> <p>Metoda: GET</p> </li> <li>URL: <code>https://localhost:8000/data/indicator/RZIS</code></li> <li> <p>Nag\u0142\u00f3wki: Dodaj odpowiednie nag\u0142\u00f3wki autoryzacji, je\u015bli s\u0105 wymagane.</p> </li> <li> <p>Po wykonaniu scenariusza, Make.com pobierze dane RZIS z Data Backbone w formacie JSON.</p> </li> </ol>"},{"location":"user-guide/api-usage/#format-odpowiedzi_1","title":"Format odpowiedzi","text":"<p>Odpowied\u017a API b\u0119dzie w formacie JSON. Przyk\u0142adowa struktura danych RZIS mo\u017ce wygl\u0105da\u0107 nast\u0119puj\u0105co:</p> <pre><code>{\n  \"data\": [\n    {\n      \"miesiac\": \"Stycze\u0144\",\n      \"przychody\": 100000,\n      \"koszty\": 80000,\n      \"zysk\": 20000\n    },\n    {\n      \"miesiac\": \"Luty\",\n      \"przychody\": 120000,\n      \"koszty\": 90000,\n      \"zysk\": 30000\n    }\n  ],\n  \"meta\": {\n    \"lastUpdated\": \"2023-06-15T10:30:00Z\"\n  }\n}\n</code></pre>"},{"location":"user-guide/api-usage/#obsuga-bedow","title":"Obs\u0142uga b\u0142\u0119d\u00f3w","text":"<p>API mo\u017ce zwr\u00f3ci\u0107 nast\u0119puj\u0105ce kody b\u0142\u0119d\u00f3w:</p> <ul> <li>400 Bad Request: Nieprawid\u0142owe zapytanie</li> <li>404 Not Found: Wska\u017anik o podanej nazwie nie istnieje</li> <li>500 Internal Server Error: B\u0142\u0105d serwera</li> </ul>"},{"location":"user-guide/api-usage/#ograniczenia","title":"Ograniczenia","text":"<ul> <li>Limit zapyta\u0144: 1000 na godzin\u0119</li> <li>Maksymalny rozmiar odpowiedzi: 10 MB</li> </ul>"},{"location":"user-guide/api-usage/#podsumowanie","title":"Podsumowanie","text":"<p>Korzystanie z API Data Backbone pozwala na \u0142atwe integrowanie danych wska\u017anik\u00f3w z zewn\u0119trznymi narz\u0119dziami. Dzi\u0119ki prostym endpointom, mo\u017cesz pobiera\u0107 aktualne dane wska\u017anik\u00f3w i wykorzystywa\u0107 je w swoich automatyzacjach i analizach.</p>"},{"location":"user-guide/data-fetching/","title":"Pobieranie danych (zasob\u00f3w)","text":""},{"location":"user-guide/data-fetching/#wprowadzenie","title":"Wprowadzenie","text":"<p>Akcja pobieraj\u0105ca to funkcja w systemie Data Backbone, kt\u00f3ra s\u0142u\u017cy do pobierania danych z zewn\u0119trznych \u017ar\u00f3de\u0142 do zasob\u00f3w (resources). Ka\u017cdy zas\u00f3b posiada w kluczu <code>action</code> okre\u015blon\u0105 akcj\u0119 pobierania, kt\u00f3ra jest g\u0142\u00f3wnym mechanizmem umo\u017cliwiaj\u0105cym zasilanie systemu danymi.</p>"},{"location":"user-guide/data-fetching/#definicja-akcji-pobierajacej","title":"Definicja Akcji Pobieraj\u0105cej","text":"<p>Akcja pobieraj\u0105ca jest zdefiniowana jako funkcja, kt\u00f3ra przyjmuje dwa parametry:</p> <ul> <li><code>Resource</code>: obiekt zasobu, kt\u00f3ry opisuje struktur\u0119 i metadane zasobu</li> <li><code>MongoClient</code>: instancja klienta MongoDB, kt\u00f3r\u0105 mo\u017cna wykorzysta\u0107 do interakcji z baz\u0105 danych</li> </ul> <p>Rezultatem tej funkcji jest lista s\u0142ownik\u00f3w, gdzie ka\u017cdy s\u0142ownik reprezentuje pojedynczy rekord danych zasobu.</p>"},{"location":"user-guide/data-fetching/#typ-akcji-pobierajacej","title":"Typ Akcji Pobieraj\u0105cej","text":"<p>Typ akcji pobieraj\u0105cej zas\u00f3b jest zdefiniowany jako:</p> <pre><code>from typing import Callable, List, Dict, Any\nfrom pymongo.mongo_client import MongoClient\nfrom config.types import Resource\n\nResourceData = List[Dict[str, Any]]\n\nResourceAction = Callable[\n   [Resource, MongoClient],\n   ResourceData\n]\n</code></pre>"},{"location":"user-guide/data-fetching/#przykadowa-implementacja","title":"Przyk\u0142adowa Implementacja","text":"<p>Oto przyk\u0142ad prostej akcji pobieraj\u0105cej, kt\u00f3ra pobiera dane z zewn\u0119trznego API.</p>"},{"location":"user-guide/data-fetching/#definiowanie-struktury-danych","title":"Definiowanie struktury danych","text":"<pre><code>schema_out = {\n    \"id\": str,\n    \"name\": str,\n    \"status\": str,\n    \"date_created\": int,\n    \"date_updated\": int,\n    \"creator_id\": int,\n    \"creator_username\": str,\n    \"creator_email\": str,\n    \"tags\": [{\n        \"name\": str,\n        \"creator\": int\n    }],\n    \"time_spent\": int,\n    \"folder_id\": int\n}\n</code></pre>"},{"location":"user-guide/data-fetching/#funkcja-morph_json_with_pandas","title":"Funkcja <code>morph_json_with_pandas</code>","text":"<p>Funkcja zmieniaj\u0105ca struktur\u0119 danych.</p> <pre><code>def morph_json_with_pandas(data: list) -&gt; Tuple[pd.DataFrame, pd.DataFrame]:\n    # Okre\u015blenie kolumn, kt\u00f3re b\u0119d\u0105 potrzebne\n    columns_wanted = [\n        'id', 'name', 'status', 'date_created', 'date_updated',\n        'creator', 'tags', 'time_spent', 'folder'\n    ]\n\n    # Konwersja danych do DataFrame\n    df = pd.DataFrame(data)\n    df = df[columns_wanted]\n\n    # Konwersja dat na typ int\n    df['date_updated'] = df['date_updated'].astype(int)\n    df['date_created'] = df['date_created'].astype(int)\n\n    # Wyci\u0105ganie i przekszta\u0142canie danych z kolumn zagnie\u017cd\u017conych struktur\n    df['status'] = df['status'].apply(lambda x: x['status'])\n    df['creator_id'] = df['creator'].apply(lambda x: x['id'])\n    df['creator_username'] = df['creator'].apply(lambda x: x['username'])\n    df['creator_email'] = df['creator'].apply(lambda x: x['email'])\n    df['folder_id'] = df['folder'].apply(lambda x: x['id']).astype(int)\n\n    # Wype\u0142nianie brakuj\u0105cych warto\u015bci i konwersja na typ int\n    df['time_spent'] = df['time_spent'].fillna(0).astype(int)\n\n    # Usuwanie zb\u0119dnych kolumn\n    df.drop(['creator', 'folder'], axis=1, inplace=True)\n\n    return Validator.validate(df,schema_out)\n</code></pre>"},{"location":"user-guide/data-fetching/#funkcja-fetch_tasks","title":"Funkcja <code>fetch_tasks</code>","text":"<p>Funkcja pobierania zasobu.</p> <pre><code>async def fetch_tasks(resource_setting: Resource, db_client: MongoClient) -&gt; list:\n    # Zak\u0142adamy, \u017ce mamy batche po 10 * 100 task\u00f3w na ten moment\n    assumed_pages = 10\n\n    # Pobieranie zada\u0144\n    data, last_page = await collect_all_tasks(resource_setting, assumed_pages)\n\n    # Przetwarzanie danych\n    valid = morph_json_with_pandas(data)\n\n    # Zwracanie poprawnych danych w formie listy s\u0142ownik\u00f3w\n    return valid.to_dict(orient='records')\n</code></pre>"},{"location":"user-guide/data-fetching/#caosc","title":"Ca\u0142o\u015b\u0107","text":"<pre><code>from __resources__.types import Resource, MongoClient\nimport pandas as pd\nfrom external_services.clickup.clickup_client import collect_all_tasks\nfrom typing import TypedDict, List, Dict, Any, Tuple\n\n# Definiowanie struktury danych wchodz\u0105cych\nschema_out = {\n    \"id\": str,\n    \"name\": str,\n    \"status\": str,\n    \"date_created\": int,\n    \"date_updated\": int,\n    \"creator_id\": int,\n    \"creator_username\": str,\n    \"creator_email\": str,\n    \"tags\": [{\n        \"name\": str,\n        \"creator\": int\n    }],\n    \"time_spent\": int,\n    \"folder_id\": int\n}\n\n# Funkcja zmieniaj\u0105ca struktur\u0119 danych\ndef morph_json_with_pandas(data: list) -&gt; Tuple[pd.DataFrame, pd.DataFrame]:\n    # Okre\u015blenie kolumn, kt\u00f3re b\u0119d\u0105 potrzebne\n    columns_wanted = [\n        'id', 'name', 'status', 'date_created', 'date_updated',\n        'creator', 'tags', 'time_spent', 'folder'\n    ]\n\n    # Konwersja danych do DataFrame\n    df = pd.DataFrame(data)\n    df = df[columns_wanted]\n\n    # Konwersja dat na typ int\n    df['date_updated'] = df['date_updated'].astype(int)\n    df['date_created'] = df['date_created'].astype(int)\n\n    # Wyci\u0105ganie i przekszta\u0142canie danych z kolumn zagnie\u017cd\u017conych struktur\n    df['status'] = df['status'].apply(lambda x: x['status'])\n    df['creator_id'] = df['creator'].apply(lambda x: x['id'])\n    df['creator_username'] = df['creator'].apply(lambda x: x['username'])\n    df['creator_email'] = df['creator'].apply(lambda x: x['email'])\n    df['folder_id'] = df['folder'].apply(lambda x: x['id']).astype(int)\n\n    # Wype\u0142nianie brakuj\u0105cych warto\u015bci i konwersja na typ int\n    df['time_spent'] = df['time_spent'].fillna(0).astype(int)\n\n    # Usuwanie zb\u0119dnych kolumn\n    df.drop(['creator', 'folder'], axis=1, inplace=True)\n\n    return Validator.validate(df, schema_out)\n\n# Funkcja pobierania zasobu\nasync def fetch_tasks(resource_setting: Resource, db_client: MongoClient) -&gt; list:\n    # Zak\u0142adamy, \u017ce mamy batche po 10 * 100 task\u00f3w na ten moment\n    assumed_pages = 10\n\n    # Pobieranie zada\u0144\n    data, last_page = await collect_all_tasks(resource_setting, assumed_pages)\n\n    # Przetwarzanie danych\n    valid = morph_json_with_pandas(data)\n\n    # Zwracanie poprawnych danych w formie listy s\u0142ownik\u00f3w\n    return valid.to_dict(orient='records')\n</code></pre>"},{"location":"user-guide/data-fetching/#podsumowanie","title":"Podsumowanie","text":"<p>Akcje pobieraj\u0105ce s\u0105 kluczowym elementem systemu Data Backbone, umo\u017cliwiaj\u0105c zasilanie zasob\u00f3w danymi z r\u00f3\u017cnych zewn\u0119trznych \u017ar\u00f3de\u0142. Dzi\u0119ki jasno zdefiniowanem typom, dobrej strukturze kodu oraz przestrzeganiu dobrych praktyk, akcje te mog\u0105 by\u0107 efektywnie i bezawaryjnie implementowane, co pozwala na pe\u0142ne wykorzystanie mo\u017cliwo\u015bci analizy danych w ramach platformy Data Backbone.</p>"},{"location":"user-guide/data-preprocessing/","title":"Przetwarzanie danych (wska\u017anik\u00f3w)","text":""},{"location":"user-guide/data-preprocessing/#wprowadzenie","title":"Wprowadzenie","text":"<p>Akcja przetwarzaj\u0105ca dane w systemie Data Backbone to funkcja, kt\u00f3ra operuje na danych zasob\u00f3w (resources) w celu wygenerowania wska\u017anik\u00f3w (indicators). Te wska\u017aniki s\u0105 kluczowymi metrykami do analizy i monitorowania r\u00f3\u017cnych aspekt\u00f3w biznesowych. Ka\u017cdy wska\u017anik posiada w kluczu <code>action</code> okre\u015blon\u0105 akcj\u0119 pobierania, kt\u00f3ra jest g\u0142\u00f3wnym mechanizmem umo\u017cliwiaj\u0105cym zasilanie systemu danymi.</p>"},{"location":"user-guide/data-preprocessing/#definicja-akcji-przetwarzajacej","title":"Definicja Akcji Przetwarzaj\u0105cej","text":"<p>Akcja przetwarzaj\u0105ca jest definiowana jako funkcja, kt\u00f3ra przyjmuje dwa parametry:</p> <ul> <li><code>Indicator</code>: obiekt wska\u017anika, kt\u00f3ry zawiera opis, struktur\u0119 i metadane wska\u017anika.</li> <li><code>MongoClient</code>: instancja klienta MongoDB, dzi\u0119ki kt\u00f3rej mo\u017cliwa jest interakcja z baz\u0105 danych.</li> </ul> <p>Rezultatem tej funkcji jest przetworzony zestaw danych, zazwyczaj w formie listy s\u0142ownik\u00f3w, gdzie ka\u017cdy s\u0142ownik reprezentuje pojedynczy zrekord danych wska\u017anika.</p>"},{"location":"user-guide/data-preprocessing/#typ-akcji-przetwarzajacej","title":"Typ Akcji Przetwarzaj\u0105cej","text":"<p>Typ akcji przetwarzaj\u0105cej dane do wska\u017anika jest zdefiniowany jako:</p> <pre><code>from typing import Callable, List, Dict, Any\nfrom pymongo.mongo_client import MongoClient\nfrom config.types import Indicator\n\nResourceData = List[Dict[str, Any]]\n\nIndicatorAction = Callable[\n   [Indicator, MongoClient],\n   ResourceData\n]\n</code></pre>"},{"location":"user-guide/data-preprocessing/#przykadowa-implementacja","title":"Przyk\u0142adowa Implementacja","text":"<p>Poni\u017cej przedstawiono przyk\u0142adow\u0105 akcj\u0119 przetwarzaj\u0105c\u0105, kt\u00f3ra agreguje dane z zasob\u00f3w do wska\u017anika.</p>"},{"location":"user-guide/data-preprocessing/#definiowanie-struktury-danych","title":"Definiowanie struktury danych","text":"<pre><code>schema_out = {\n    \"client\": str,\n    \"id\": str,\n    \"date\": str,\n    \"mapped_payments_to_worklogs\": [\n        {\n            \"cycle_number\": int,\n            \"log_info\": [\n                {\n                    \"date_of_log\": str,\n                    \"worked_time\": float,\n                    \"user_name\": str,\n                    \"task_name\": str,\n                    \"task_id\": str,\n                    \"task_tag_name\": (str, type(None)),\n                    \"description\": str\n                }\n            ]\n        }\n    ]\n}\n</code></pre>"},{"location":"user-guide/data-preprocessing/#funkcja-map_payments_to_all_worklogs","title":"Funkcja <code>map_payments_to_all_worklogs</code>","text":"<p>Funkcja przetwarzaj\u0105ca struktury danych.</p> <pre><code>def map_payments_to_all_worklogs(worklogs, invoices, tasks):\n    # Konwertuj listy na DataFrame\n    worklogs_df = pd.DataFrame(worklogs)\n    invoices_df = pd.DataFrame(invoices)\n    tasks_df = pd.DataFrame(tasks)\n\n    # Sortowanie faktur wed\u0142ug daty stworzenia (od najstarszej do najnowszej) i resetowanie indeksu\n    sorted_invoices = invoices_df.sort_values(by='created').reset_index(drop=True)\n\n    # Konwersja kolumny 'created' na datetime\n    sorted_invoices['created'] = pd.to_datetime(sorted_invoices['created'], unit='s')\n\n    # Tworzenie kolumny 'end_of_cycle'\n    sorted_invoices['end_of_cycle'] = sorted_invoices['created'].shift(-1)\n    sorted_invoices.loc[sorted_invoices.index[-1], 'end_of_cycle'] = sorted_invoices['created'].iloc[-1] + pd.Timedelta(days=14)\n\n    # Dodanie kolumny 'cycle_number'\n    sorted_invoices['cycle_number'] = np.arange(1, len(sorted_invoices) + 1)\n\n    # Tworzenie DataFrame mapped_invoices_to_cycles\n    mapped_invoices_to_cycles_df = sorted_invoices[['cycle_number', 'created', 'end_of_cycle']].rename(columns={'created': 'invoice_creation_date_object'})\n\n    # Znalezienie wszystkich dziennik\u00f3w pracy dla cykli\n    mapped_worklogs_to_invoices = find_all_logs_for_cycles(mapped_invoices_to_cycles_df, worklogs_df, tasks_df)\n\n    # Zwr\u00f3\u0107 zmapowane dzienniki pracy do faktur\n    return mapped_worklogs_to_invoices\n</code></pre>"},{"location":"user-guide/data-preprocessing/#funkcja-build_worklogs_with_cycle_number","title":"Funkcja <code>build_worklogs_with_cycle_number</code>","text":"<p>G\u0142\u00f3wna funkcja przetwarzaj\u0105ca.</p> <pre><code>def build_worklogs_with_cycle_number(indicator_setting: Indicator, db_client: MongoClient):\n    # Pobierz dane z zasob\u00f3w StripeInvoices i ClickupTimeEntries\n    stripe_invoices = list(db_client['RESOURCES']['StripeInvoices'].find())\n    clickup_time_entries = list(db_client['RESOURCES']['ClickupTimeEntries'].find())\n    clickup_tasks = list(db_client['RESOURCES']['ClickupTasks'].find())\n    clients = list(db_client['RESOURCES']['ClientMapping'].find())\n\n    final_results = pd.DataFrame(columns=['client', 'id', 'date', 'mapped_payments_to_worklogs'])\n\n    for client in clients:\n        filtered_invoices = filter_stripe_invoices(stripe_invoices, client['stripe_customer_id'])\n        filtered_time_entries = filter_clickup_entries(clickup_time_entries, client['clickup_folder_id'])\n        filtered_tasks = filter_clickup_tasks(clickup_tasks, int(client['clickup_folder_id']))\n\n        mapped_payments_to_worklogs = map_payments_to_worklogs_from_first_invoice(filtered_time_entries, filtered_invoices, filtered_tasks)\n\n        new_row = {\n            'client': client['company_name'],\n            'id': client['company_name'],\n            'date': datetime.now().strftime('%Y-%m-%d'),\n            'mapped_payments_to_worklogs': mapped_payments_to_worklogs\n        }\n        final_results = pd.concat([final_results, pd.DataFrame([new_row])], ignore_index=True)\n\n    return Validator.validate(final_results, schema_out).to_dict(orient='records')\n</code></pre>"},{"location":"user-guide/data-preprocessing/#caosc","title":"Ca\u0142o\u015b\u0107","text":"<pre><code>from collections import OrderedDict, defaultdict\nimport uuid\nimport pandas as pd\nimport numpy as np\nfrom __indicators__.types import Indicator, MongoClient\nfrom datetime import datetime, timedelta\nfrom decimal import Decimal\n\nfrom __indicators__.utils.build_worklogs_with_cycle_number import (\n    filter_clickup_entries,\n    filter_clickup_tasks,\n    filter_stripe_invoices,\n    map_payments_to_worklogs_from_first_invoice,\n    find_all_logs_for_cycles\n)\n\n# Funkcja przetwarzaj\u0105ca struktury danych\ndef map_payments_to_all_worklogs(worklogs, invoices, tasks):\n    # Konwertuj listy na DataFrame\n    worklogs_df = pd.DataFrame(worklogs)\n    invoices_df = pd.DataFrame(invoices)\n    tasks_df = pd.DataFrame(tasks)\n\n    # Sortowanie faktur wed\u0142ug daty stworzenia (od najstarszej do najnowszej) i resetowanie indeksu\n    sorted_invoices = invoices_df.sort_values(by='created').reset_index(drop=True)\n\n    # Konwersja kolumny 'created' na datetime\n    sorted_invoices['created'] = pd.to_datetime(sorted_invoices['created'], unit='s')\n\n    # Tworzenie kolumny 'end_of_cycle'\n    sorted_invoices['end_of_cycle'] = sorted_invoices['created'].shift(-1)\n    sorted_invoices.loc[sorted_invoices.index[-1], 'end_of_cycle'] = sorted_invoices['created'].iloc[-1] + pd.Timedelta(days=14)\n\n    # Dodanie kolumny 'cycle_number'\n    sorted_invoices['cycle_number'] = np.arange(1, len(sorted_invoices) + 1)\n\n    # Tworzenie DataFrame mapped_invoices_to_cycles\n    mapped_invoices_to_cycles_df = sorted_invoices[['cycle_number', 'created', 'end_of_cycle']].rename(columns={'created': 'invoice_creation_date_object'})\n\n    # Znalezienie wszystkich dziennik\u00f3w pracy dla cykli\n    mapped_worklogs_to_invoices = find_all_logs_for_cycles(mapped_invoices_to_cycles_df, worklogs_df, tasks_df)\n\n    # Zwr\u00f3\u0107 zmapowane dzienniki pracy do faktur\n    return mapped_worklogs_to_invoices\n\n# Definiowanie struktury danych\nschema_out = {\n    \"client\": str,\n    \"id\": str,\n    \"date\": str,\n    \"mapped_payments_to_worklogs\": [\n        {\n            \"cycle_number\": int,\n            \"log_info\": [\n                {\n                    \"date_of_log\": str,\n                    \"worked_time\": float,\n                    \"user_name\": str,\n                    \"task_name\": str,\n                    \"task_id\": str,\n                    \"task_tag_name\": (str, type(None)),\n                    \"description\": str\n                }\n            ]\n        }\n    ]\n}\n\n# G\u0142\u00f3wna funkcja przetwarzaj\u0105ca\ndef build_worklogs_with_cycle_number(indicator_setting: Indicator, db_client: MongoClient):\n    # Pobierz dane z zasob\u00f3w StripeInvoices i ClickupTimeEntries\n    stripe_invoices = list(db_client['RESOURCES']['StripeInvoices'].find())\n    clickup_time_entries = list(db_client['RESOURCES']['ClickupTimeEntries'].find())\n    clickup_tasks = list(db_client['RESOURCES']['ClickupTasks'].find())\n    clients = list(db_client['RESOURCES']['ClientMapping'].find())\n\n    final_results = pd.DataFrame(columns=['client', 'id', 'date', 'mapped_payments_to_worklogs'])\n\n    for client in clients:\n        filtered_invoices = filter_stripe_invoices(stripe_invoices, client['stripe_customer_id'])\n        filtered_time_entries = filter_clickup_entries(clickup_time_entries, client['clickup_folder_id'])\n        filtered_tasks = filter_clickup_tasks(clickup_tasks, int(client['clickup_folder_id']))\n\n        mapped_payments_to_worklogs = map_payments_to_worklogs_from_first_invoice(filtered_time_entries, filtered_invoices, filtered_tasks)\n\n        new_row = {\n            'client': client['company_name'],\n            'id': client['company_name'],\n            'date': datetime.now().strftime('%Y-%m-%d'),\n            'mapped_payments_to_worklogs': mapped_payments_to_worklogs\n        }\n        final_results = pd.concat([final_results, pd.DataFrame([new_row])], ignore_index=True)\n\n    return Validator.validate(final_results, schema_out).to_dict(orient='records')\n</code></pre>"},{"location":"user-guide/data-preprocessing/#podsumowanie","title":"Podsumowanie","text":"<p>Akcje przetwarzaj\u0105ce s\u0105 kluczowym elementem systemu Data Backbone, umo\u017cliwiaj\u0105c generowanie warto\u015bciowych wska\u017anik\u00f3w na podstawie surowych danych zasob\u00f3w. Dzi\u0119ki jasno zdefiniowanym typom, dobrze zorganizowanemu kodu oraz przestrzeganiu sprawdzonych praktyk, akcje te mog\u0105 by\u0107 skutecznie i niezawodnie implementowane, co pozwala na pe\u0142ne wykorzystanie mo\u017cliwo\u015bci analizy danych w ramach platformy Data Backbone.</p>"},{"location":"user-guide/data-sync/","title":"Synchronizacja danych","text":""},{"location":"user-guide/data-sync/#wprowadzenie","title":"Wprowadzenie","text":"<p>Data Backbone to narz\u0119dzie, kt\u00f3re pomaga firmom M\u015aP w analizie danych z r\u00f3\u017cnych \u017ar\u00f3de\u0142. Czasami zachodzi potrzeba r\u0119cznej synchronizacji danych zasob\u00f3w i wska\u017anik\u00f3w. Poni\u017cej znajduj\u0105 si\u0119 instrukcje, jak wykona\u0107 te operacje.</p>"},{"location":"user-guide/data-sync/#synchronizacja-reczna-zasobow-i-wskaznikow","title":"Synchronizacja R\u0119czna Zasob\u00f3w i Wska\u017anik\u00f3w","text":"<p>Istnieje kilka metod r\u0119cznej synchronizacji zasob\u00f3w i wska\u017anik\u00f3w. Ka\u017cda z nich jest realizowana poprzez wywo\u0142anie odpowiedniego adresu URL w przegl\u0105darce lub za pomoc\u0105 narz\u0119dzia do wykonywania zapyta\u0144 HTTP (np. <code>curl</code>, Postman).</p>"},{"location":"user-guide/data-sync/#synchronizacja-pojedynczego-zasobu","title":"Synchronizacja Pojedynczego Zasobu","text":"<p>Aby zsynchronizowa\u0107 pojedynczy zas\u00f3b, taki jak <code>ExampleResource.json</code>, u\u017cyj poni\u017cszego URL:</p> <pre><code>curl -X GET localhost:8000/refresh-data/resources/ExampleResource\n</code></pre>"},{"location":"user-guide/data-sync/#synchronizacja-pojedynczego-wskaznika","title":"Synchronizacja Pojedynczego Wska\u017anika","text":"<p>Aby zsynchronizowa\u0107 pojedynczy wska\u017anik, taki jak <code>ExampleIndicator.json</code>, u\u017cyj poni\u017cszego URL:</p> <pre><code>curl -X GET localhost:8000/refresh-data/indicators/ExampleIndicator\n</code></pre>"},{"location":"user-guide/data-sync/#synchronizacja-wszystkich-zasobow","title":"Synchronizacja Wszystkich Zasob\u00f3w","text":"<p>Aby zsynchronizowa\u0107 wszystkie zasoby, u\u017cyj poni\u017cszego URL:</p> <pre><code>curl -X GET localhost:8000/refresh-data/resources\n</code></pre>"},{"location":"user-guide/data-sync/#synchronizacja-wszystkich-wskaznikow","title":"Synchronizacja Wszystkich Wska\u017anik\u00f3w","text":"<p>Aby zsynchronizowa\u0107 wszystkie wska\u017aniki, u\u017cyj poni\u017cszego URL:</p> <pre><code>curl -X GET localhost:8000/refresh-data/indicators\n</code></pre>"},{"location":"user-guide/data-sync/#synchronizacja-wszystkich-zasobow-i-wskaznikow","title":"Synchronizacja Wszystkich Zasob\u00f3w i Wska\u017anik\u00f3w","text":"<p>Aby zsynchronizowa\u0107 wszystkie zasoby i wska\u017aniki jednocze\u015bnie, u\u017cyj poni\u017cszego URL:</p> <pre><code>curl -X GET localhost:8000/refresh-data/all\n</code></pre>"},{"location":"user-guide/data-sync/#podsumowanie","title":"Podsumowanie","text":"<p>R\u0119czna synchronizacja zasob\u00f3w i wska\u017anik\u00f3w w Data Backbone jest prosta i szybka. Wystarczy u\u017cy\u0107 odpowiednich adres\u00f3w URL, aby zsynchronizowa\u0107 konkretne zasoby, wska\u017aniki lub wszystkie dane na raz. Dzi\u0119ki temu mo\u017cesz \u0142atwo utrzymywa\u0107 swoje dane w aktualnym stanie, co pozwala na lepsz\u0105 analiz\u0119 i podejmowanie decyzji na podstawie aktualnych informacji.</p>"},{"location":"utils/logging-debugging/","title":"Logowanie i debugowanie","text":""},{"location":"utils/logging-debugging/#wprowadzenie","title":"Wprowadzenie","text":"<p>System Data Backbone oferuje mo\u017cliwo\u015bci logowania i debugowania dzi\u0119ki klasie <code>Logger</code>. Ta klasa umo\u017cliwia efektywne \u015bledzenie dzia\u0142a\u0144 systemu, co jest kluczowe dla utrzymania i rozwi\u0105zywania problem\u00f3w.</p>"},{"location":"utils/logging-debugging/#klasa-logger","title":"Klasa Logger","text":"<p>Klasa <code>Logger</code> jest g\u0142\u00f3wnym narz\u0119dziem do logowania w systemie Data Backbone.</p>"},{"location":"utils/logging-debugging/#inicjalizacja","title":"Inicjalizacja","text":"<p>Aby utworzy\u0107 instancj\u0119 loggera, u\u017cyj nast\u0119puj\u0105cego kodu:</p> <pre><code>logger = Logger(log_file='logfile.log')\n</code></pre> <p>Parametr <code>log_file</code> jest opcjonalny i domy\u015blnie ustawiony na 'logfile.log'.</p>"},{"location":"utils/logging-debugging/#metody","title":"Metody","text":""},{"location":"utils/logging-debugging/#logmessage-str-none","title":"log(message: str) -&gt; None","text":"<p>Metoda <code>log</code> zapisuje wiadomo\u015b\u0107 z aktualnym znacznikiem czasu.</p> <p>Przyk\u0142ad u\u017cycia:</p> <pre><code>logger.log(\"Rozpocz\u0119to przetwarzanie danych\")\n</code></pre>"},{"location":"utils/logging-debugging/#_write_to_filemessage-str-none","title":"_write_to_file(message: str) -&gt; None","text":"<p>Metoda prywatna <code>_write_to_file</code> zapisuje wiadomo\u015b\u0107 do pliku log\u00f3w.</p>"},{"location":"utils/logging-debugging/#format-logow","title":"Format log\u00f3w","text":"<p>Ka\u017cdy wpis w logu ma nast\u0119puj\u0105cy format:</p> <pre><code>[RRRR-MM-DD GG:MM:SS] Tre\u015b\u0107 wiadomo\u015bci\n</code></pre>"},{"location":"utils/logging-debugging/#dobre-praktyki","title":"Dobre praktyki","text":"<ol> <li>U\u017cywaj logowania do \u015bledzenia kluczowych operacji w systemie.</li> <li>Zapisuj zar\u00f3wno informacje o sukcesach, jak i b\u0142\u0119dach.</li> <li>Regularnie przegl\u0105daj logi w celu wykrycia potencjalnych problem\u00f3w.</li> </ol>"},{"location":"utils/logging-debugging/#podsumowanie","title":"Podsumowanie","text":"<p>Klasa <code>Logger</code> w Data Backbone zapewnia prosty, ale skuteczny mechanizm logowania. Dzi\u0119ki niej mo\u017cesz \u0142atwo \u015bledzi\u0107 dzia\u0142anie systemu, co jest nieocenione w procesie debugowania i utrzymania aplikacji.</p>"},{"location":"utils/parallel/","title":"Dzia\u0142ania r\u00f3wnoleg\u0142e","text":""},{"location":"utils/parallel/#wprowadzenie","title":"Wprowadzenie","text":"<p>Data Backbone oferuje mechanizmy do wykonywania operacji r\u00f3wnoleg\u0142ych, co pozwala na efektywne przetwarzanie du\u017cych ilo\u015bci danych. W tym rozdziale om\u00f3wimy kluczowe komponenty umo\u017cliwiaj\u0105ce r\u00f3wnoleg\u0142e dzia\u0142ania: klas\u0119 <code>BatchRequest</code> oraz klas\u0119 <code>BatchFunction</code>, a tak\u017ce przedstawimy przyk\u0142ad ich praktycznego zastosowania.</p>"},{"location":"utils/parallel/#klasa-batchrequest","title":"Klasa BatchRequest","text":"<p><code>BatchRequest</code> to klasa umo\u017cliwiaj\u0105ca wykonywanie r\u00f3wnoleg\u0142ych \u017c\u0105da\u0144 HTTP.</p>"},{"location":"utils/parallel/#gowne-metody","title":"G\u0142\u00f3wne metody","text":"<pre><code>async def __aenter__(self):\n    # Inicjalizacja sesji aiohttp\n\nasync def __aexit__(self, exc_type, exc_val, exc_tb):\n    # Zamkni\u0119cie sesji aiohttp\n\nasync def get_batch(self, requests: List[RequestInfo]) -&gt; List[str]:\n    # Wykonanie wielu \u017c\u0105da\u0144 HTTP r\u00f3wnolegle\n</code></pre>"},{"location":"utils/parallel/#kluczowe-cechy","title":"Kluczowe cechy","text":"<ul> <li>Wykorzystanie kontekstu asynchronicznego (<code>async with</code>)</li> <li>R\u00f3wnoleg\u0142e wykonywanie wielu \u017c\u0105da\u0144 HTTP</li> <li>Automatyczne zarz\u0105dzanie sesj\u0105 aiohttp</li> </ul>"},{"location":"utils/parallel/#klasa-batchfunction","title":"Klasa BatchFunction","text":"<p><code>BatchFunction</code> to klasa do wykonywania funkcji w partiach, wspieraj\u0105ca zar\u00f3wno funkcje synchroniczne, jak i asynchroniczne.</p>"},{"location":"utils/parallel/#gowne-metody_1","title":"G\u0142\u00f3wne metody","text":"<pre><code>def __init__(self, func: Callable[..., Any], batch_size: int = 10):\n    # Inicjalizacja z funkcj\u0105 do wykonania i rozmiarem partii\n\n@staticmethod\nasync def run_batch(func: Callable[..., Any], param_list: List[Tuple[Tuple[Any, ...], dict]], batch_size: int = 10) -&gt; List[Any]:\n    # Statyczna metoda do wykonywania funkcji w partiach\n</code></pre>"},{"location":"utils/parallel/#kluczowe-cechy_1","title":"Kluczowe cechy","text":"<ul> <li>Obs\u0142uga zar\u00f3wno funkcji synchronicznych, jak i asynchronicznych</li> <li>Wykonywanie funkcji w partiach o okre\u015blonym rozmiarze</li> <li>Mo\u017cliwo\u015b\u0107 u\u017cycia jako kontekst asynchroniczny lub poprzez metod\u0119 statyczn\u0105</li> </ul>"},{"location":"utils/parallel/#przykad-uzycia-pobieranie-zadan-z-clickup","title":"Przyk\u0142ad u\u017cycia: Pobieranie zada\u0144 z ClickUp","text":"<p>Funkcja <code>collect_all_tasks</code> demonstruje praktyczne zastosowanie mechanizm\u00f3w r\u00f3wnoleg\u0142ego przetwarzania w kontek\u015bcie pobierania danych z zewn\u0119trznego API.</p>"},{"location":"utils/parallel/#implementacja","title":"Implementacja","text":"<pre><code>async def collect_all_tasks(resource_setting: Resource, pages=10):\n    # Konfiguracja autoryzacji i parametr\u00f3w zapytania\n    # ...\n\n    requests = []\n    for i in range(pages):\n        # Przygotowanie zapyta\u0144 dla ka\u017cdej strony\n        # ...\n\n    async with BatchRequest() as getter:\n        # R\u00f3wnoleg\u0142e wykonanie zapyta\u0144\n        results = await getter.get_batch(requests)\n\n        # Przetwarzanie wynik\u00f3w\n        # ...\n\n    return accumulator, with_last_page\n</code></pre>"},{"location":"utils/parallel/#kluczowe-aspekty-przykadu","title":"Kluczowe aspekty przyk\u0142adu","text":"<ul> <li>Wykorzystanie <code>BatchRequest</code> do r\u00f3wnoleg\u0142ego wykonywania wielu zapyta\u0144 HTTP</li> <li>Obs\u0142uga paginacji w API ClickUp</li> <li>Efektywne gromadzenie danych z wielu stron wynik\u00f3w</li> </ul>"},{"location":"utils/parallel/#podsumowanie","title":"Podsumowanie","text":"<p>Mechanizmy r\u00f3wnoleg\u0142ego przetwarzania w Data Backbone, reprezentowane przez klasy <code>BatchRequest</code> i <code>BatchFunction</code>, umo\u017cliwiaj\u0105 efektywne zarz\u0105dzanie du\u017cymi ilo\u015bciami danych. Przyk\u0142ad funkcji <code>collect_all_tasks</code> pokazuje, jak te mechanizmy mog\u0105 by\u0107 praktycznie zastosowane do optymalizacji pobierania danych z zewn\u0119trznych API, znacz\u0105co zwi\u0119kszaj\u0105c wydajno\u015b\u0107 operacji na du\u017cych zbiorach danych.</p>"}]}